{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_data_final version.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,np.r_[0:2,3:6,9:11]]\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.set_index(['product_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Style - Nanchun (Aslan) Shi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select columns to be used for embedding model\n",
    "\n",
    "emb_df = df1.loc[:,['description','details']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import from self-created module; check Preprocessing.py for details\n",
    "\n",
    "from Preprocessing import embedding_preprocessing\n",
    "emb_pre = embedding_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing\n",
    "\n",
    "emb_vector_df = pd.DataFrame(emb_pre.preprocess(emb_df), index = emb_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load embedding model\n",
    "\n",
    "emb_model = load_model('style_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict\n",
    "\n",
    "emb_pred_vectors = emb_model.predict(emb_vector_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select columns to be used for tf-idf model\n",
    "\n",
    "tfidf_df = df1.loc[:,['brand','product_full_name','brand_category','brand_canonical_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import from self-created module; check Preprocessing.py for details\n",
    "\n",
    "from Preprocessing import tfidf_preprocessing\n",
    "tfidf_pre = tfidf_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing\n",
    "\n",
    "tfidf_vector_df = tfidf_pre.preprocess(tfidf_df).set_index(tfidf_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load tf-idf model\n",
    "\n",
    "tfidf_model = load_model('style_tfidf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict\n",
    "\n",
    "tfidf_pred_vectors = tfidf_model.predict(tfidf_vector_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_classes(mat):\n",
    "    pred = list(map(lambda v: list(np.argsort(v))[-2:], mat))\n",
    "    return np.array(pred)\n",
    "\n",
    "label_dict = load_obj('style_label_dict_rev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vectors = 0.4*emb_pred_vectors + 0.6*tfidf_pred_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_classes = get_pred_classes(final_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['style_prediction'] = list(map(lambda x: [label_dict[x[0]], label_dict[x[1]]], final_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>style_prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>[modern, businesscasual]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>[businesscasual, classic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>[casual, classic]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      brand  \\\n",
       "product_id                                    \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416  Banana Republic   \n",
       "01DSE9SKM19XNA6SJP36JZC065  Banana Republic   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN            Loewe   \n",
       "\n",
       "                                               product_full_name  \\\n",
       "product_id                                                         \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416                      Ankle-Strap Pump   \n",
       "01DSE9SKM19XNA6SJP36JZC065                   Petite Tie-Neck Top   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN  52MM Padded Leather Round Sunglasses   \n",
       "\n",
       "                                                                  description  \\\n",
       "product_id                                                                      \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416  A modern pump, in a rounded silhouette with an...   \n",
       "01DSE9SKM19XNA6SJP36JZC065  Dress it down with jeans and sneakers or dress...   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN    Padded leather covers classic round sunglasses.   \n",
       "\n",
       "                                                               brand_category  \\\n",
       "product_id                                                                      \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416                                            Unknown   \n",
       "01DSE9SKM19XNA6SJP36JZC065                                            Unknown   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "\n",
       "                                                          brand_canonical_url  \\\n",
       "product_id                                                                      \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416  https://bananarepublic.gap.com/browse/product....   \n",
       "01DSE9SKM19XNA6SJP36JZC065  https://bananarepublic.gap.com/browse/product....   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "\n",
       "                                                                      details  \\\n",
       "product_id                                                                      \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416  A modern pump, in a rounded silhouette with an...   \n",
       "01DSE9SKM19XNA6SJP36JZC065  Dress it down with jeans and sneakers or dress...   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN  100% UV protection Case and cleaning cloth inc...   \n",
       "\n",
       "                                     style_prediction  \n",
       "product_id                                             \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416   [modern, businesscasual]  \n",
       "01DSE9SKM19XNA6SJP36JZC065  [businesscasual, classic]  \n",
       "01DSJX8GD4DSAP76SPR85HRCMN          [casual, classic]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Fit - Xinyi (Alex) Guo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('full_data_final version.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunctuation(text, punctuations=string.punctuation+\"``\"+\"’\"+\"”\"):\n",
    "    words=nltk.word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in punctuations]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = set(stopwords.words(\"English\"))\n",
    "def removeStopwords(text, stopwords=nltk_stopwords):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in stopwords]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatizedWords = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "    lemmatizedText = \" \".join(lemmatizedWords)\n",
    "    return lemmatizedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, columns = [\"brand\", \"product_full_name\", \"description\", \"details\"]):\n",
    "    df['details'] = df['details'].str.replace(\"\\n\", \"\")\n",
    "    #replace null values with UNKNOWN_TOKEN\n",
    "    df['brand'] = df['brand'].fillna('UNKNOWN_TOKEN')\n",
    "    df['description'] = df['description'].fillna('UNKNOWN_TOKEN')\n",
    "    df['details'] = df['details'].fillna('UNKNOWN_TOKEN')\n",
    "    df['product_full_name'] = df['product_full_name'].fillna('UNKNOWN_TOKEN')\n",
    "    #remove punctuation and stopwords then lemmatize\n",
    "    for col in columns: \n",
    "        df[col] = df[col].apply(removePunctuation)\n",
    "        df[col] = df[col].apply(removeStopwords)\n",
    "        df[col] = df[col].apply(lemmatize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Keras Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_token_length_per_doc(docs):\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test_df, target, max_length):\n",
    "    #load data\n",
    "    X_test_df[\"input_doc\"] = X_test_df.brand + \" \" + X_test_df.product_full_name + \" \" \\\n",
    "                                + X_test_df.description + \" \" + X_test_df.details \n",
    "    X_test = X_test_df.loc[:, \"input_doc\"].values\n",
    "    test_docs = list(X_test)\n",
    "\n",
    "    #load model\n",
    "    model = load_model(\"{}_model.h5\".format(target))\n",
    "    with open('{}_tokenizer.pickle'.format(target), 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "        \n",
    "    #predict\n",
    "    encoded_test_docs = integer_encode_documents(test_docs, tokenizer)\n",
    "    padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "    prediction_proba = model.predict(padded_test_docs, verbose = 0)\n",
    "    \n",
    "    return prediction_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df):\n",
    "    '''\n",
    "    This function will predict the fit of the clothing. It takes a dataframe as an input. The CSV file needs to have \n",
    "    \"brand\", \"product_full_name\", \"description\", and \"details\" columns. The function will output a dataframe with an \n",
    "    additional fit column. \n",
    "    '''\n",
    "    #load data\n",
    "#     inputFile = input(\"What's the name of the csv file? (ex. full_data.csv)\")\n",
    "    fullData = df\n",
    "    #Preprocess data\n",
    "    print(\"Start preprocessing data...\")\n",
    "    testData = fullData.copy()\n",
    "    testData = testData.loc[:, [\"brand\", \"product_full_name\", \"description\", \"details\"]]\n",
    "    testData = preprocessing(testData)\n",
    "    print(\"Start predicting fit...\")\n",
    "    #Predict fit\n",
    "    maxLengthDict = {'straightregular': 185,\n",
    "                 'semifitted': 185,\n",
    "                 'relaxed': 202,\n",
    "                 'oversized': 202,\n",
    "                 'fittedtailored': 202}\n",
    "    prob_df = pd.DataFrame()\n",
    "    fitType = ['straightregular', 'semifitted', 'relaxed', 'oversized', 'fittedtailored']\n",
    "    for fit in fitType:\n",
    "        prediction_proba = predict(testData, target = fit, max_length = maxLengthDict[fit])\n",
    "        prob_df[fit] = prediction_proba.flatten()\n",
    "        print(fit, \"fit prediction done\")\n",
    "    prob_df['predict_fit'] = prob_df.idxmax(axis=1)\n",
    "    fullData['fit'] = prob_df['predict_fit']\n",
    "#     fullData.to_csv(\"full_data with fit prediction.csv\")\n",
    "    return fullData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preprocessing data...\n",
      "Start predicting fit...\n",
      "straightregular fit prediction done\n",
      "semifitted fit prediction done\n",
      "relaxed fit prediction done\n",
      "oversized fit prediction done\n",
      "fittedtailored fit prediction done\n"
     ]
    }
   ],
   "source": [
    "df2 = main(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>514683</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:37:15.719107+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straightregular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>526676</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:36:50.682513+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>4.001E+11</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>2019-11-13 17:33:59.581661+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DSJVKJNS6F4KQ1QM6YYK9AW2</td>\n",
       "      <td>Converse</td>\n",
       "      <td>4.00012E+11</td>\n",
       "      <td>Baby's &amp; Little Kid's All-Star Two-Tone Mid-To...</td>\n",
       "      <td>The iconic mid-top design gets an added dose o...</td>\n",
       "      <td>JustKids/Shoes/Baby024Months/BabyGirl,JustKids...</td>\n",
       "      <td>2019-11-13 17:05:05.203733+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/converse-babys...</td>\n",
       "      <td>Canvas upper Round toe Lace-up vamp SmartFOAM ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DSK15ZD4D5A0QXA8NSD25YXE</td>\n",
       "      <td>Alexander McQueen</td>\n",
       "      <td>4.00011E+11</td>\n",
       "      <td>64MM Rimless Sunglasses</td>\n",
       "      <td>Hexagonal shades offer a rimless view with int...</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval</td>\n",
       "      <td>2019-11-13 18:42:30.941321+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/alexander-mcqu...</td>\n",
       "      <td>100% UV protection Gradient lenses Adjustable ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id              brand          mpn  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416    Banana Republic       514683   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065    Banana Republic       526676   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN              Loewe    4.001E+11   \n",
       "3  01DSJVKJNS6F4KQ1QM6YYK9AW2           Converse  4.00012E+11   \n",
       "4  01DSK15ZD4D5A0QXA8NSD25YXE  Alexander McQueen  4.00011E+11   \n",
       "\n",
       "                                   product_full_name  \\\n",
       "0                                   Ankle-Strap Pump   \n",
       "1                                Petite Tie-Neck Top   \n",
       "2               52MM Padded Leather Round Sunglasses   \n",
       "3  Baby's & Little Kid's All-Star Two-Tone Mid-To...   \n",
       "4                            64MM Rimless Sunglasses   \n",
       "\n",
       "                                         description  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2    Padded leather covers classic round sunglasses.   \n",
       "3  The iconic mid-top design gets an added dose o...   \n",
       "4  Hexagonal shades offer a rimless view with int...   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "3  JustKids/Shoes/Baby024Months/BabyGirl,JustKids...   \n",
       "4     JewelryAccessories/SunglassesReaders/RoundOval   \n",
       "\n",
       "                      created_at                     updated_at deleted_at  \\\n",
       "0  2019-11-11 22:37:15.719107+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "1  2019-11-11 22:36:50.682513+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "2  2019-11-13 17:33:59.581661+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "3  2019-11-13 17:05:05.203733+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "4  2019-11-13 18:42:30.941321+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "3  https://www.saksfifthavenue.com/converse-babys...   \n",
       "4  https://www.saksfifthavenue.com/alexander-mcqu...   \n",
       "\n",
       "                                             details            labels  \\\n",
       "0  A modern pump, in a rounded silhouette with an...  {\"Needs Review\"}   \n",
       "1  Dress it down with jeans and sneakers or dress...  {\"Needs Review\"}   \n",
       "2  100% UV protection Case and cleaning cloth inc...  {\"Needs Review\"}   \n",
       "3  Canvas upper Round toe Lace-up vamp SmartFOAM ...  {\"Needs Review\"}   \n",
       "4  100% UV protection Gradient lenses Adjustable ...  {\"Needs Review\"}   \n",
       "\n",
       "   bc_product_id              fit  \n",
       "0            NaN  straightregular  \n",
       "1            NaN       semifitted  \n",
       "2            NaN       semifitted  \n",
       "3            NaN       semifitted  \n",
       "4            NaN          relaxed  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Occasion - Bingru Xue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df3.columns:\n",
    "    df3[i] = df3[i].str.lower()\n",
    "df3= df3.replace(np.nan, 'UNKNOWN_TOKEN', regex=True)\n",
    "df3['details'] = df3['details'].str.replace(\"\\n\", \"\")\n",
    "df3['text'] = df3['description']+' '+df3['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    #remove stopwords and do lemmatization\n",
    "    doc = nlp(sentence)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df3['text'] = df3['text'].apply(preprocess_text)\n",
    "df3['product_full_name'] = df3['product_full_name'].apply(preprocess_text)\n",
    "df3['brand_category'] = df3['brand_category'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_url(url):\n",
    "    url = re.sub('https://www.', '', url)\n",
    "    url = re.sub('.com', '', url)\n",
    "    url = re.sub('/', ' ', url)\n",
    "    url = re.sub('-', ' ', url)\n",
    "    url = re.sub(r'[0-9]+', ' ', url)\n",
    "    url = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', url)\n",
    "    url = re.sub(r'\\s+', ' ', url)\n",
    "\n",
    "    doc = nlp(url)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df3['brand_canonical_url'] = df3['brand_canonical_url'].apply(preprocess_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['brand_info'] = df3['brand']+' '+df3['product_full_name']+' '+\\\n",
    "                    df3['brand_category']+' '+df3['brand_canonical_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Embedding Model: Description & Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df3['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id\n",
       "01DSE9TC2DQXDG6GWKW9NMJ416    modern pump rounded silhouette ankle strap ext...\n",
       "01DSE9SKM19XNA6SJP36JZC065    dress jean sneaker dress tailored trouser heel...\n",
       "01DSJX8GD4DSAP76SPR85HRCMN    padded leather cover classic round sunglass uv...\n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2    iconic mid design get add dose support padded ...\n",
       "01DSK15ZD4D5A0QXA8NSD25YXE    UNKNOWN_TOKEN shade offer UNKNOWN_TOKEN view i...\n",
       "                                                    ...                        \n",
       "01DSNVXY8EJ9FQAJ3MPDMPASHD    unknown token cozy double breasted jacket craf...\n",
       "01DSGYHA3RMCHENBJVQPBGXM97    UNKNOWN_TOKEN hour long wear water resistant U...\n",
       "01DSJT8H12CAFQQH07SQSQWJ8C    ruffle trim sweatshirt lend romance striped le...\n",
       "01DSH2PF9J7QZ44D842B3GMCFN    pretty plaid dress velvet collar velvet bow po...\n",
       "01DSH54D3PWHKFZK5A8A2JE3RQ    unknown token corduroy dress bow cotton cordur...\n",
       "Name: text, Length: 48090, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "tokenizer = load_obj(\"occasion_tokeniver\")\n",
    "new_doc = []\n",
    "def replace_oov(sentence):\n",
    "    now_sen =[]\n",
    "    for word in word_tokenize(sentence):\n",
    "        if word in tokenizer.word_index.keys():\n",
    "            now_sen.append(word)\n",
    "        else:\n",
    "            now_sen.append(\"UNKNOWN_TOKEN\")\n",
    "    return \" \".join(now_sen)\n",
    "docs.apply(replace_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "token = tokenizer.texts_to_sequences(docs)\n",
    "pad = pad_sequences(token, padding='post', maxlen=165, truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = load_model('occasion_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "occasion_type = [\"cold weather\",\"day to night\",\"night out\",\"vacation\",\"weekend\",\"work\",\"workout\"]\n",
    "pred = embedding_model.predict(pad)\n",
    "embedding_df = pd.DataFrame(data= pred, columns = occasion_type,index=df3.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Vectorization Model: Brand, Name, URL, Brand Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = df3['brand_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = load_obj(\"occasion_vectorizer\")\n",
    "vector = vectorizer.transform(info)\n",
    "tf_idf_df = pd.DataFrame(vector.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "occasion_type = [\"cold weather\",\"day to night\",\"night out\",\"vacation\",\"weekend\",\"work\",\"workout\"]\n",
    "vector_df = pd.DataFrame(columns = occasion_type, index = df3.index)\n",
    "\n",
    "for label in occasion_type:\n",
    "    filename = \"{}\".format(label)+\"_vector_model\"\n",
    "    vector_model = load_obj(filename)\n",
    "    prob = vector_model.predict_proba(vector)[:,1]\n",
    "    vector_df[label] = prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Combine embedding model and vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "occasion_result_df = 0.4*embedding_df + 0.6*vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cold weather</th>\n",
       "      <th>day to night</th>\n",
       "      <th>night out</th>\n",
       "      <th>vacation</th>\n",
       "      <th>weekend</th>\n",
       "      <th>work</th>\n",
       "      <th>workout</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01DSE9TC2DQXDG6GWKW9NMJ416</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSE9SKM19XNA6SJP36JZC065</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSJX8GD4DSAP76SPR85HRCMN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSJVKJNS6F4KQ1QM6YYK9AW2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSK15ZD4D5A0QXA8NSD25YXE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSNVXY8EJ9FQAJ3MPDMPASHD</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSGYHA3RMCHENBJVQPBGXM97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSJT8H12CAFQQH07SQSQWJ8C</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSH2PF9J7QZ44D842B3GMCFN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSH54D3PWHKFZK5A8A2JE3RQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48090 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cold weather  day to night  night out  vacation  \\\n",
       "product_id                                                                    \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416           0.0           1.0        0.0       0.0   \n",
       "01DSE9SKM19XNA6SJP36JZC065           0.0           1.0        0.0       0.0   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN           0.0           0.0        0.0       1.0   \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2           0.0           1.0        0.0       0.0   \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE           0.0           0.0        0.0       0.0   \n",
       "...                                  ...           ...        ...       ...   \n",
       "01DSNVXY8EJ9FQAJ3MPDMPASHD           1.0           1.0        0.0       0.0   \n",
       "01DSGYHA3RMCHENBJVQPBGXM97           0.0           0.0        0.0       1.0   \n",
       "01DSJT8H12CAFQQH07SQSQWJ8C           0.0           1.0        0.0       0.0   \n",
       "01DSH2PF9J7QZ44D842B3GMCFN           0.0           0.0        0.0       0.0   \n",
       "01DSH54D3PWHKFZK5A8A2JE3RQ           0.0           0.0        0.0       0.0   \n",
       "\n",
       "                            weekend  work  workout  \n",
       "product_id                                          \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416      0.0   0.0      0.0  \n",
       "01DSE9SKM19XNA6SJP36JZC065      1.0   1.0      0.0  \n",
       "01DSJX8GD4DSAP76SPR85HRCMN      1.0   0.0      0.0  \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2      1.0   0.0      0.0  \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE      1.0   0.0      0.0  \n",
       "...                             ...   ...      ...  \n",
       "01DSNVXY8EJ9FQAJ3MPDMPASHD      1.0   0.0      0.0  \n",
       "01DSGYHA3RMCHENBJVQPBGXM97      1.0   0.0      0.0  \n",
       "01DSJT8H12CAFQQH07SQSQWJ8C      1.0   0.0      0.0  \n",
       "01DSH2PF9J7QZ44D842B3GMCFN      1.0   0.0      0.0  \n",
       "01DSH54D3PWHKFZK5A8A2JE3RQ      1.0   0.0      0.0  \n",
       "\n",
       "[48090 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decision(probs):\n",
    "    if sum(probs>0.5)>0:\n",
    "        probs[probs > 0.5] = 1\n",
    "        probs[probs <= 0.5] = 0\n",
    "    else:\n",
    "        probs[probs == np.max(probs)] = 1\n",
    "        probs[probs != np.max(probs)] = 0\n",
    "    return probs\n",
    "\n",
    "occasion_result_df.apply(decision, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "occasion = []\n",
    "for i in occasion_result_df.index:\n",
    "    label = []\n",
    "    for j in occasion_result_df.columns:\n",
    "        if occasion_result_df.loc[i,j].any():\n",
    "            label.append(j)\n",
    "    occasion.append(label)\n",
    "occasion_result_df['Occasion'] = occasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cold weather</th>\n",
       "      <th>day to night</th>\n",
       "      <th>night out</th>\n",
       "      <th>vacation</th>\n",
       "      <th>weekend</th>\n",
       "      <th>work</th>\n",
       "      <th>workout</th>\n",
       "      <th>Occasion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01DSE9TC2DQXDG6GWKW9NMJ416</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[day to night]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSE9SKM19XNA6SJP36JZC065</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[day to night, weekend, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSJX8GD4DSAP76SPR85HRCMN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[vacation, weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSJVKJNS6F4KQ1QM6YYK9AW2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[day to night, weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSK15ZD4D5A0QXA8NSD25YXE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSNVXY8EJ9FQAJ3MPDMPASHD</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[cold weather, day to night, weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSGYHA3RMCHENBJVQPBGXM97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[vacation, weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSJT8H12CAFQQH07SQSQWJ8C</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[day to night, weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSH2PF9J7QZ44D842B3GMCFN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSH54D3PWHKFZK5A8A2JE3RQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[weekend]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48090 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cold weather  day to night  night out  vacation  \\\n",
       "product_id                                                                    \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416           0.0           1.0        0.0       0.0   \n",
       "01DSE9SKM19XNA6SJP36JZC065           0.0           1.0        0.0       0.0   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN           0.0           0.0        0.0       1.0   \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2           0.0           1.0        0.0       0.0   \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE           0.0           0.0        0.0       0.0   \n",
       "...                                  ...           ...        ...       ...   \n",
       "01DSNVXY8EJ9FQAJ3MPDMPASHD           1.0           1.0        0.0       0.0   \n",
       "01DSGYHA3RMCHENBJVQPBGXM97           0.0           0.0        0.0       1.0   \n",
       "01DSJT8H12CAFQQH07SQSQWJ8C           0.0           1.0        0.0       0.0   \n",
       "01DSH2PF9J7QZ44D842B3GMCFN           0.0           0.0        0.0       0.0   \n",
       "01DSH54D3PWHKFZK5A8A2JE3RQ           0.0           0.0        0.0       0.0   \n",
       "\n",
       "                            weekend  work  workout  \\\n",
       "product_id                                           \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416      0.0   0.0      0.0   \n",
       "01DSE9SKM19XNA6SJP36JZC065      1.0   1.0      0.0   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN      1.0   0.0      0.0   \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2      1.0   0.0      0.0   \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE      1.0   0.0      0.0   \n",
       "...                             ...   ...      ...   \n",
       "01DSNVXY8EJ9FQAJ3MPDMPASHD      1.0   0.0      0.0   \n",
       "01DSGYHA3RMCHENBJVQPBGXM97      1.0   0.0      0.0   \n",
       "01DSJT8H12CAFQQH07SQSQWJ8C      1.0   0.0      0.0   \n",
       "01DSH2PF9J7QZ44D842B3GMCFN      1.0   0.0      0.0   \n",
       "01DSH54D3PWHKFZK5A8A2JE3RQ      1.0   0.0      0.0   \n",
       "\n",
       "                                                         Occasion  \n",
       "product_id                                                         \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416                         [day to night]  \n",
       "01DSE9SKM19XNA6SJP36JZC065          [day to night, weekend, work]  \n",
       "01DSJX8GD4DSAP76SPR85HRCMN                    [vacation, weekend]  \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2                [day to night, weekend]  \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE                              [weekend]  \n",
       "...                                                           ...  \n",
       "01DSNVXY8EJ9FQAJ3MPDMPASHD  [cold weather, day to night, weekend]  \n",
       "01DSGYHA3RMCHENBJVQPBGXM97                    [vacation, weekend]  \n",
       "01DSJT8H12CAFQQH07SQSQWJ8C                [day to night, weekend]  \n",
       "01DSH2PF9J7QZ44D842B3GMCFN                              [weekend]  \n",
       "01DSH54D3PWHKFZK5A8A2JE3RQ                              [weekend]  \n",
       "\n",
       "[48090 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occasion_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "occasion_final = occasion_result_df.loc[:,\"Occasion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Patterns/Prints - Jiayue (Daniel) Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('full_data_final version.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null values with UNKNOWN_TOKEN\n",
    "full_data['description'] = full_data['description'].fillna('UNKNOWN_TOKEN')\n",
    "full_data['details'] = full_data['details'].fillna('UNKNOWN_TOKEN')\n",
    "full_data['brand_category'] = full_data['brand_category'].fillna('UNKNOWN_TOKEN')\n",
    "full_data['details'] = full_data['details'].str.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "# define a function to remove punctuation\n",
    "def removePunctuation(text, punctuations=string.punctuation+\"``\"+\"’\"+\"”\"):\n",
    "    words=nltk.word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in punctuations]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText\n",
    "\n",
    "nltk_stopwords = set(stopwords.words(\"English\"))\n",
    "\n",
    "# define a function to remove stopwords\n",
    "def removeStopwords(text, stopwords=nltk_stopwords):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in stopwords]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText\n",
    "\n",
    "# define a function to lemmatize all texts\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatizedWords = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "    lemmatizedText = \" \".join(lemmatizedWords)\n",
    "    return lemmatizedText\n",
    "\n",
    "columns = [\"brand\", \"product_full_name\", \"description\", \"details\"]\n",
    "for col in columns: \n",
    "    full_data[col] = full_data[col].apply(removePunctuation)\n",
    "    full_data[col] = full_data[col].apply(removeStopwords)\n",
    "    full_data[col] = full_data[col].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['abstract'] = 0\n",
    "full_data['animal'] = 0\n",
    "full_data['camouflage'] = 0\n",
    "full_data['colorblock'] = 0\n",
    "full_data['dots'] = 0\n",
    "full_data['floral'] = 0\n",
    "full_data['geometric'] = 0\n",
    "full_data['graphic'] = 0\n",
    "full_data['houndstooth'] = 0\n",
    "full_data['logo'] = 0\n",
    "full_data['monogram'] = 0\n",
    "full_data['multiprint'] = 0\n",
    "full_data['paisley'] = 0\n",
    "full_data['pinstripe'] = 0\n",
    "full_data['plaid'] = 0\n",
    "full_data['stripe'] = 0\n",
    "full_data['stripehorizontal'] = 0\n",
    "full_data['stripevertical'] = 0\n",
    "full_data['tiedye'] = 0\n",
    "full_data['tropical'] = 0\n",
    "full_data[\"input_doc\"] = full_data.brand+\" \"+full_data.product_full_name+\" \"+full_data.description+\" \"+full_data.details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Modeling & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "def get_max_token_length_per_doc(docs):\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the complete pattern's file, we generate a list of max_length\n",
    "max_length_list = [150, 150, 124, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "pattern_values = list(full_data.columns.values[13:33])\n",
    "for i in range(13, 33):\n",
    "    X_test = full_data.iloc[:, -1].values\n",
    "    test_docs = list(X_test)\n",
    "    model = load_model(\"{}_model.h5\".format(pattern_values[i-13]))\n",
    "    with open('{}_tokenizer.pickle'.format(pattern_values[i-13]), 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "        \n",
    "   #predict\n",
    "    encoded_test_docs = integer_encode_documents(test_docs, tokenizer)\n",
    "    padded_test_docs = pad_sequences(encoded_test_docs, maxlen = max_length_list[i-13], padding = 'post')\n",
    "    prediction = model.predict(padded_test_docs, verbose = 0)\n",
    "    full_data.iloc[:, i] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = full_data.iloc[:, 13:33]\n",
    "df4['patterns/prints'] = df4.idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "      <th>patterns/prints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>514683</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:37:15.719107+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>526676</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:36:50.682513+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>floral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>4.001E+11</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>2019-11-13 17:33:59.581661+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>01DSJVKJNS6F4KQ1QM6YYK9AW2</td>\n",
       "      <td>Converse</td>\n",
       "      <td>4.00012E+11</td>\n",
       "      <td>Baby's &amp; Little Kid's All-Star Two-Tone Mid-To...</td>\n",
       "      <td>The iconic mid-top design gets an added dose o...</td>\n",
       "      <td>JustKids/Shoes/Baby024Months/BabyGirl,JustKids...</td>\n",
       "      <td>2019-11-13 17:05:05.203733+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/converse-babys...</td>\n",
       "      <td>Canvas upper Round toe Lace-up vamp SmartFOAM ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>01DSK15ZD4D5A0QXA8NSD25YXE</td>\n",
       "      <td>Alexander McQueen</td>\n",
       "      <td>4.00011E+11</td>\n",
       "      <td>64MM Rimless Sunglasses</td>\n",
       "      <td>Hexagonal shades offer a rimless view with int...</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval</td>\n",
       "      <td>2019-11-13 18:42:30.941321+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/alexander-mcqu...</td>\n",
       "      <td>100% UV protection Gradient lenses Adjustable ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id              brand          mpn  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416    Banana Republic       514683   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065    Banana Republic       526676   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN              Loewe    4.001E+11   \n",
       "3  01DSJVKJNS6F4KQ1QM6YYK9AW2           Converse  4.00012E+11   \n",
       "4  01DSK15ZD4D5A0QXA8NSD25YXE  Alexander McQueen  4.00011E+11   \n",
       "\n",
       "                                   product_full_name  \\\n",
       "0                                   Ankle-Strap Pump   \n",
       "1                                Petite Tie-Neck Top   \n",
       "2               52MM Padded Leather Round Sunglasses   \n",
       "3  Baby's & Little Kid's All-Star Two-Tone Mid-To...   \n",
       "4                            64MM Rimless Sunglasses   \n",
       "\n",
       "                                         description  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2    Padded leather covers classic round sunglasses.   \n",
       "3  The iconic mid-top design gets an added dose o...   \n",
       "4  Hexagonal shades offer a rimless view with int...   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "3  JustKids/Shoes/Baby024Months/BabyGirl,JustKids...   \n",
       "4     JewelryAccessories/SunglassesReaders/RoundOval   \n",
       "\n",
       "                      created_at                     updated_at deleted_at  \\\n",
       "0  2019-11-11 22:37:15.719107+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "1  2019-11-11 22:36:50.682513+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "2  2019-11-13 17:33:59.581661+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "3  2019-11-13 17:05:05.203733+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "4  2019-11-13 18:42:30.941321+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "3  https://www.saksfifthavenue.com/converse-babys...   \n",
       "4  https://www.saksfifthavenue.com/alexander-mcqu...   \n",
       "\n",
       "                                             details            labels  \\\n",
       "0  A modern pump, in a rounded silhouette with an...  {\"Needs Review\"}   \n",
       "1  Dress it down with jeans and sneakers or dress...  {\"Needs Review\"}   \n",
       "2  100% UV protection Case and cleaning cloth inc...  {\"Needs Review\"}   \n",
       "3  Canvas upper Round toe Lace-up vamp SmartFOAM ...  {\"Needs Review\"}   \n",
       "4  100% UV protection Gradient lenses Adjustable ...  {\"Needs Review\"}   \n",
       "\n",
       "   bc_product_id patterns/prints  \n",
       "0            NaN          animal  \n",
       "1            NaN          floral  \n",
       "2            NaN            logo  \n",
       "3            NaN            logo  \n",
       "4            NaN          animal  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.read_csv('full_data_final version.csv')\n",
    "full_data['patterns/prints'] = df4['patterns/prints']\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Category - Yuyao Shen \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import spacy\n",
    "punctuations = string.punctuation\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    use regular expression to clean text \n",
    "    replace numbers and units to variables\n",
    "    '''\n",
    "    p = re.compile(r'<.*?>')\n",
    "    text = p.sub('', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\xa0', '',text)\n",
    "    text = re.sub(r'\\d{1,3}(\\.|\\’)?\\d{1,3}?(\\\"|\\”)',\"length_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?%',\"percentage_val\", text)\n",
    "    text = text.strip(string.punctuation).replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?mm',\"mm_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?cm',\"cm_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?(inches|inch)',\"inches_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?(lbs|kg)',\"weight_val\", text)\n",
    "    text = re.sub(r'size\\s*?\\d{1,3}\\s*?',\"size_val\", text)\n",
    "    text = re.sub(r'\\b\\d+\\b',' ',text)\n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    mytokens = parser(text)\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "    return \" \".join(mytokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cate_test(inputFile):\n",
    "    '''\n",
    "    Input testing dataset that is going to be labeled\n",
    "    Keep relevant columns \n",
    "    Basic cleaning\n",
    "    Output cleaned testing dataset for category in a dataframe\n",
    "    '''\n",
    "    #full_test_data = pd.read_csv(inputFile)\n",
    "    full_test_data = df5  \n",
    "    ### keep relevant columns only\n",
    "    test_data = full_test_data[['product_full_name', 'details','description', 'brand_category']]\n",
    "    ### fill null values with 'Unknown_token'\n",
    "    test_data.fillna('Unknown_token', inplace = True)\n",
    "    X_test = test_data['product_full_name'] + ' '+ test_data['details'] + ' '+test_data['description']+ ' '+test_data['brand_category']\n",
    "    return test_data, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_classes(mat):\n",
    "    pred = list(map(lambda v: list(np.argsort(v))[-1:], mat))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data, X_test = clean_cate_test('full_data_final version.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading vectorizer\n",
    "Pkl_Filename = \"category_token.pkl\"  \n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    tk = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### vectorize incoming data\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "vector_text_test = tk.texts_to_sequences(X_test)\n",
    "padded_token_lists_test = pad_sequences(vector_text_test, maxlen=175, padding='post')\n",
    "X_test = pd.DataFrame(padded_token_lists_test, index = full_test_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3  Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading model\n",
    "Pkl_Filename = \"category_model.pkl\"  \n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use trained model to predict incoming data\n",
    "pred_vectors_test = model.predict(X_test)\n",
    "test_pred_classes = get_pred_classes(pred_vectors_test)\n",
    "categories = ['accessory', 'bottom', 'onepiece', 'shoe', 'top']\n",
    "cate_pred = [categories[i[0]] for i in test_pred_classes]\n",
    "predicted_test = pd.Series(cate_pred).str.capitalize() \n",
    "df5['category']  = list(predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01DSE9TC2DQXDG6GWKW9NMJ416</th>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSE9SKM19XNA6SJP36JZC065</th>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Onepiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSJX8GD4DSAP76SPR85HRCMN</th>\n",
       "      <td>Loewe</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>Accessory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSJVKJNS6F4KQ1QM6YYK9AW2</th>\n",
       "      <td>Converse</td>\n",
       "      <td>Baby's &amp; Little Kid's All-Star Two-Tone Mid-To...</td>\n",
       "      <td>The iconic mid-top design gets an added dose o...</td>\n",
       "      <td>JustKids/Shoes/Baby024Months/BabyGirl,JustKids...</td>\n",
       "      <td>https://www.saksfifthavenue.com/converse-babys...</td>\n",
       "      <td>Canvas upper Round toe Lace-up vamp SmartFOAM ...</td>\n",
       "      <td>Shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DSK15ZD4D5A0QXA8NSD25YXE</th>\n",
       "      <td>Alexander McQueen</td>\n",
       "      <td>64MM Rimless Sunglasses</td>\n",
       "      <td>Hexagonal shades offer a rimless view with int...</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval</td>\n",
       "      <td>https://www.saksfifthavenue.com/alexander-mcqu...</td>\n",
       "      <td>100% UV protection Gradient lenses Adjustable ...</td>\n",
       "      <td>Accessory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        brand  \\\n",
       "product_id                                      \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416    Banana Republic   \n",
       "01DSE9SKM19XNA6SJP36JZC065    Banana Republic   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN              Loewe   \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2           Converse   \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE  Alexander McQueen   \n",
       "\n",
       "                                                            product_full_name  \\\n",
       "product_id                                                                      \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416                                   Ankle-Strap Pump   \n",
       "01DSE9SKM19XNA6SJP36JZC065                                Petite Tie-Neck Top   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN               52MM Padded Leather Round Sunglasses   \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2  Baby's & Little Kid's All-Star Two-Tone Mid-To...   \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE                            64MM Rimless Sunglasses   \n",
       "\n",
       "                                                                  description  \\\n",
       "product_id                                                                      \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416  A modern pump, in a rounded silhouette with an...   \n",
       "01DSE9SKM19XNA6SJP36JZC065  Dress it down with jeans and sneakers or dress...   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN    Padded leather covers classic round sunglasses.   \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2  The iconic mid-top design gets an added dose o...   \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE  Hexagonal shades offer a rimless view with int...   \n",
       "\n",
       "                                                               brand_category  \\\n",
       "product_id                                                                      \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416                                            Unknown   \n",
       "01DSE9SKM19XNA6SJP36JZC065                                            Unknown   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2  JustKids/Shoes/Baby024Months/BabyGirl,JustKids...   \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE     JewelryAccessories/SunglassesReaders/RoundOval   \n",
       "\n",
       "                                                          brand_canonical_url  \\\n",
       "product_id                                                                      \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416  https://bananarepublic.gap.com/browse/product....   \n",
       "01DSE9SKM19XNA6SJP36JZC065  https://bananarepublic.gap.com/browse/product....   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2  https://www.saksfifthavenue.com/converse-babys...   \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE  https://www.saksfifthavenue.com/alexander-mcqu...   \n",
       "\n",
       "                                                                      details  \\\n",
       "product_id                                                                      \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416  A modern pump, in a rounded silhouette with an...   \n",
       "01DSE9SKM19XNA6SJP36JZC065  Dress it down with jeans and sneakers or dress...   \n",
       "01DSJX8GD4DSAP76SPR85HRCMN  100% UV protection Case and cleaning cloth inc...   \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2  Canvas upper Round toe Lace-up vamp SmartFOAM ...   \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE  100% UV protection Gradient lenses Adjustable ...   \n",
       "\n",
       "                             category  \n",
       "product_id                             \n",
       "01DSE9TC2DQXDG6GWKW9NMJ416       Shoe  \n",
       "01DSE9SKM19XNA6SJP36JZC065   Onepiece  \n",
       "01DSJX8GD4DSAP76SPR85HRCMN  Accessory  \n",
       "01DSJVKJNS6F4KQ1QM6YYK9AW2       Shoe  \n",
       "01DSK15ZD4D5A0QXA8NSD25YXE  Accessory  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['style'] = df1.style_prediction\n",
    "df['fit'] = df2.fit\n",
    "df['occasion'] = df3.Occasion\n",
    "df['patterns/prints'] = full_data['patterns/prints']\n",
    "df['category'] = df5.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
