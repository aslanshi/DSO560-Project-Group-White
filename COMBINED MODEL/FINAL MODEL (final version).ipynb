{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook is the combined version of all codes from each group member's work. This notebook will take a dataframe as input and output the predictions for 5 attribute for the products. All predictions will be appended as 5 new columns to the orginial input. There are 6 sections: the first 5 are for predictions, and the last one if for appending and outputing. If one is interested in certain sections, one could check the individual folders in our repo, which contain individual works. If one has further interests or questions, there are contact information on the home page. \n",
    "\n",
    "## Instruction\n",
    "\n",
    "Two kinds of inputs are allowed: CSV file or user input. \n",
    "\n",
    "- If the input is a Comma-separated values (csv) file, each row should represent a product and columns **must** include 'product_id','brand','product_full_name','brand_category','brand_canonical_url','description','details'. Column names should **match the forms** (spelling, underscore, and lowercase) above. Null values are allowed. Run the \"**CSV Input**\" cell below and change the file name to the input file name. It's originally full_data, which we got from our client. \n",
    "\n",
    "- If user wants to type in columns values, please use the \"**User Input**\" cell. Type in the values in the way shown in the example. \n",
    "\n",
    "**Please use the following Dropbox link to downlaod a zip file/folder, which contains all the supplements for this notebook. Please unzip them and make sure all files are in the same folder as this notebook:**\n",
    "\n",
    "https://www.dropbox.com/s/1p7098qkp0i2wzk/Group_White_Final_Model_Files.zip?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "import string \n",
    "from keras.models import load_model\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_data_final version.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,['product_id','brand','product_full_name','description','brand_category','brand_canonical_url','details']]\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## below is an example of how to input data; if there is null value, please use np.nan as entry\n",
    "## example:\n",
    "\n",
    "product_id = ['id1','id2']\n",
    "brand = ['brand1','brand2']\n",
    "product_full_name = ['fullname1','fullname2']\n",
    "brand_category = ['cate1','cate2']\n",
    "brand_canonical_url = ['url1','url2']\n",
    "description = ['desp1', np.nan]\n",
    "details = [np.nan, 'detail2']\n",
    "\n",
    "df = pd.DataFrame(dict(zip(['product_id','brand','product_full_name','brand_category','brand_canonical_url','description','details'],\n",
    "                      [product_id,brand,product_full_name,brand_category,brand_canonical_url,description,details])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Style - Nanchun (Aslan) Shi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select columns to be used for embedding model\n",
    "\n",
    "emb_df = df1.loc[:,['description','details']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import from self-created module; check Preprocessing.py for details\n",
    "\n",
    "from Preprocessing import embedding_preprocessing\n",
    "emb_pre = embedding_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing\n",
    "\n",
    "emb_vector_df = pd.DataFrame(emb_pre.preprocess(emb_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load embedding model\n",
    "\n",
    "emb_model = load_model('style_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict\n",
    "\n",
    "emb_pred_vectors = emb_model.predict(emb_vector_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select columns to be used for tf-idf model\n",
    "\n",
    "tfidf_df = df1.loc[:,['brand','product_full_name','brand_category','brand_canonical_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import from self-created module; check Preprocessing.py for details\n",
    "\n",
    "from Preprocessing import tfidf_preprocessing\n",
    "tfidf_pre = tfidf_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing\n",
    "\n",
    "tfidf_vector_df = tfidf_pre.preprocess(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load tf-idf model\n",
    "\n",
    "tfidf_model = load_model('style_tfidf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict\n",
    "\n",
    "tfidf_pred_vectors = tfidf_model.predict(tfidf_vector_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_classes(mat):\n",
    "    pred = list(map(lambda v: list(np.argsort(v))[-2:], mat))\n",
    "    return np.array(pred)\n",
    "\n",
    "label_dict = load_obj('style_label_dict_rev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vectors = 0.4*emb_pred_vectors + 0.6*tfidf_pred_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_classes = get_pred_classes(final_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['style_prediction'] = list(map(lambda x: [label_dict[x[0]], label_dict[x[1]]], final_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>style_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>[modern, businesscasual]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>[businesscasual, classic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>[casual, classic]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id            brand  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416  Banana Republic   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065  Banana Republic   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN            Loewe   \n",
       "\n",
       "                      product_full_name  \\\n",
       "0                      Ankle-Strap Pump   \n",
       "1                   Petite Tie-Neck Top   \n",
       "2  52MM Padded Leather Round Sunglasses   \n",
       "\n",
       "                                         description  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2    Padded leather covers classic round sunglasses.   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "\n",
       "                                             details  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2  100% UV protection Case and cleaning cloth inc...   \n",
       "\n",
       "            style_prediction  \n",
       "0   [modern, businesscasual]  \n",
       "1  [businesscasual, classic]  \n",
       "2          [casual, classic]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Fit - Xinyi (Alex) Guo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunctuation(text, punctuations=string.punctuation+\"``\"+\"’\"+\"”\"):\n",
    "    words=nltk.word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in punctuations]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = set(stopwords.words(\"English\"))\n",
    "def removeStopwords(text, stopwords=nltk_stopwords):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in stopwords]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatizedWords = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "    lemmatizedText = \" \".join(lemmatizedWords)\n",
    "    return lemmatizedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, columns = [\"brand\", \"product_full_name\", \"description\", \"details\"]):\n",
    "    df['details'] = df['details'].str.replace(\"\\n\", \"\")\n",
    "    #replace null values with UNKNOWN_TOKEN\n",
    "    df['brand'] = df['brand'].fillna('UNKNOWN_TOKEN')\n",
    "    df['description'] = df['description'].fillna('UNKNOWN_TOKEN')\n",
    "    df['details'] = df['details'].fillna('UNKNOWN_TOKEN')\n",
    "    df['product_full_name'] = df['product_full_name'].fillna('UNKNOWN_TOKEN')\n",
    "    #remove punctuation and stopwords then lemmatize\n",
    "    for col in columns: \n",
    "        df[col] = df[col].apply(removePunctuation)\n",
    "        df[col] = df[col].apply(removeStopwords)\n",
    "        df[col] = df[col].apply(lemmatize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Keras Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_token_length_per_doc(docs):\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test_df, target, max_length):\n",
    "    #load data\n",
    "    X_test_df[\"input_doc\"] = X_test_df.brand + \" \" + X_test_df.product_full_name + \" \" \\\n",
    "                                + X_test_df.description + \" \" + X_test_df.details \n",
    "    X_test = X_test_df.loc[:, \"input_doc\"].values\n",
    "    test_docs = list(X_test)\n",
    "\n",
    "    #load model\n",
    "    model = load_model(\"{}_model.h5\".format(target))\n",
    "    with open('{}_tokenizer.pickle'.format(target), 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "        \n",
    "    #predict\n",
    "    encoded_test_docs = integer_encode_documents(test_docs, tokenizer)\n",
    "    padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "    prediction_proba = model.predict(padded_test_docs, verbose = 0)\n",
    "    \n",
    "    return prediction_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df):\n",
    "    '''\n",
    "    This function will predict the fit of the clothing. It takes a dataframe as an input. The CSV file needs to have \n",
    "    \"brand\", \"product_full_name\", \"description\", and \"details\" columns. The function will output a dataframe with an \n",
    "    additional fit column. \n",
    "    '''\n",
    "    #load data\n",
    "#     inputFile = input(\"What's the name of the csv file? (ex. full_data.csv)\")\n",
    "    fullData = df\n",
    "    #Preprocess data\n",
    "    print(\"Start preprocessing data...\")\n",
    "    testData = fullData.copy()\n",
    "    testData = testData.loc[:, [\"brand\", \"product_full_name\", \"description\", \"details\"]]\n",
    "    testData = preprocessing(testData)\n",
    "    print(\"Start predicting fit...\")\n",
    "    #Predict fit\n",
    "    maxLengthDict = {'straightregular': 185,\n",
    "                 'semifitted': 185,\n",
    "                 'relaxed': 202,\n",
    "                 'oversized': 202,\n",
    "                 'fittedtailored': 202}\n",
    "    prob_df = pd.DataFrame()\n",
    "    fitType = ['straightregular', 'semifitted', 'relaxed', 'oversized', 'fittedtailored']\n",
    "    for fit in fitType:\n",
    "        prediction_proba = predict(testData, target = fit, max_length = maxLengthDict[fit])\n",
    "        prob_df[fit] = prediction_proba.flatten()\n",
    "        print(fit, \"fit prediction done\")\n",
    "    prob_df['predict_fit'] = prob_df.idxmax(axis=1)\n",
    "    fullData['fit'] = prob_df['predict_fit']\n",
    "#     fullData.to_csv(\"full_data with fit prediction.csv\")\n",
    "    return fullData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preprocessing data...\n",
      "Start predicting fit...\n",
      "straightregular fit prediction done\n",
      "semifitted fit prediction done\n",
      "relaxed fit prediction done\n",
      "oversized fit prediction done\n",
      "fittedtailored fit prediction done\n"
     ]
    }
   ],
   "source": [
    "df2 = main(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>straightregular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id            brand  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416  Banana Republic   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065  Banana Republic   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN            Loewe   \n",
       "\n",
       "                      product_full_name  \\\n",
       "0                      Ankle-Strap Pump   \n",
       "1                   Petite Tie-Neck Top   \n",
       "2  52MM Padded Leather Round Sunglasses   \n",
       "\n",
       "                                         description  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2    Padded leather covers classic round sunglasses.   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "\n",
       "                                             details              fit  \n",
       "0  A modern pump, in a rounded silhouette with an...  straightregular  \n",
       "1  Dress it down with jeans and sneakers or dress...       semifitted  \n",
       "2  100% UV protection Case and cleaning cloth inc...       semifitted  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Occasion - Bingru Xue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change text to lower case and replace null values\n",
    "for i in df3.columns:\n",
    "    df3[i] = df3[i].str.lower()\n",
    "df3= df3.replace(np.nan, 'UNKNOWN_TOKEN', regex=True)\n",
    "df3['details'] = df3['details'].str.replace(\"\\n\", \"\")\n",
    "df3['text'] = df3['description']+' '+df3['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    #remove stopwords and do lemmatization\n",
    "    doc = nlp(sentence)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df3['text'] = df3['text'].apply(preprocess_text)\n",
    "df3['product_full_name'] = df3['product_full_name'].apply(preprocess_text)\n",
    "df3['brand_category'] = df3['brand_category'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_url(url):\n",
    "    url = re.sub('https://www.', '', url)\n",
    "    url = re.sub('.com', '', url)\n",
    "    url = re.sub('/', ' ', url)\n",
    "    url = re.sub('-', ' ', url)\n",
    "    url = re.sub(r'[0-9]+', ' ', url)\n",
    "    url = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', url)\n",
    "    url = re.sub(r'\\s+', ' ', url)\n",
    "\n",
    "    doc = nlp(url)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df3['brand_canonical_url'] = df3['brand_canonical_url'].apply(preprocess_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['brand_info'] = df3['brand']+' '+df3['product_full_name']+' '+\\\n",
    "                    df3['brand_category']+' '+df3['brand_canonical_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Embedding Model: Description & Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df3['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        modern pump rounded silhouette ankle strap ext...\n",
       "1        dress jean sneaker dress tailor trouser heel t...\n",
       "2        padded leather cover classic round sunglass uv...\n",
       "3        iconic mid design get add dose support padded ...\n",
       "4        UNKNOWN_TOKEN shade offer UNKNOWN_TOKEN view i...\n",
       "                               ...                        \n",
       "48085    unknown token cozy double breasted jacket craf...\n",
       "48086    UNKNOWN_TOKEN hour long wear water resistant U...\n",
       "48087    ruffled trim sweatshirt lend romance stripe le...\n",
       "48088    pretty plaid dress velvet collar velvet bow po...\n",
       "48089    unknown token corduroy dress bow cotton cordur...\n",
       "Name: text, Length: 48090, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace words in new input that are out-of-vocabulary to a single token\n",
    "tokenizer = load_obj(\"occasion_tokeniver\")\n",
    "new_doc = []\n",
    "def replace_oov(sentence):\n",
    "    now_sen =[]\n",
    "    for word in word_tokenize(sentence):\n",
    "        if word in tokenizer.word_index.keys():\n",
    "            now_sen.append(word)\n",
    "        else:\n",
    "            now_sen.append(\"UNKNOWN_TOKEN\")\n",
    "    return \" \".join(now_sen)\n",
    "docs.apply(replace_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad documents\n",
    "\n",
    "token = tokenizer.texts_to_sequences(docs)\n",
    "pad = pad_sequences(token, padding='post', maxlen=165, truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in trained model for word embedding\n",
    "\n",
    "embedding_model = load_model('occasion_embedding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probability of a product belonging to each of occasion type\n",
    "\n",
    "occasion_type = [\"cold weather\",\"day to night\",\"night out\",\"vacation\",\"weekend\",\"work\",\"workout\"]\n",
    "pred = embedding_model.predict(pad)\n",
    "embedding_df = pd.DataFrame(data= pred, columns = occasion_type,index=df3.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Vectorization Model: Brand, Name, URL, Brand Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = df3['brand_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in TF-IDF Vectorizer and transform new input\n",
    "\n",
    "vectorizer = load_obj(\"occasion_vectorizer\")\n",
    "vector = vectorizer.transform(info)\n",
    "tf_idf_df = pd.DataFrame(vector.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probability of a product belonging to each of occasion type using corresponding trained model\n",
    "\n",
    "occasion_type = [\"cold weather\",\"day to night\",\"night out\",\"vacation\",\"weekend\",\"work\",\"workout\"]\n",
    "vector_df = pd.DataFrame(columns = occasion_type, index = df3.index)\n",
    "\n",
    "for label in occasion_type:\n",
    "    filename = \"{}\".format(label)+\"_vector_model\"\n",
    "    vector_model = load_obj(filename)\n",
    "    prob = vector_model.predict_proba(vector)[:,1]\n",
    "    vector_df[label] = prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Combine embedding model and vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weighted average predicted probability from 2 models\n",
    "\n",
    "occasion_result_df = 0.4*embedding_df + 0.6*vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cold weather</th>\n",
       "      <th>day to night</th>\n",
       "      <th>night out</th>\n",
       "      <th>vacation</th>\n",
       "      <th>weekend</th>\n",
       "      <th>work</th>\n",
       "      <th>workout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48090 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cold weather  day to night  night out  vacation  weekend  work  workout\n",
       "0               0.0           1.0        0.0       0.0      0.0   0.0      0.0\n",
       "1               0.0           1.0        0.0       0.0      1.0   1.0      0.0\n",
       "2               0.0           0.0        0.0       1.0      1.0   0.0      0.0\n",
       "3               0.0           1.0        0.0       0.0      1.0   0.0      0.0\n",
       "4               0.0           0.0        0.0       0.0      1.0   0.0      0.0\n",
       "...             ...           ...        ...       ...      ...   ...      ...\n",
       "48085           1.0           1.0        0.0       0.0      1.0   0.0      0.0\n",
       "48086           0.0           0.0        0.0       1.0      1.0   0.0      0.0\n",
       "48087           0.0           1.0        0.0       0.0      1.0   0.0      0.0\n",
       "48088           0.0           0.0        0.0       0.0      1.0   0.0      0.0\n",
       "48089           0.0           0.0        0.0       0.0      1.0   0.0      0.0\n",
       "\n",
       "[48090 rows x 7 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision rule:\n",
    "# If a product's probability of belonging to an occasion type is >0.5, assign this occasion\n",
    "# If none of occasion probability is >0.5 for a product, assign with occasion with highest probability\n",
    "\n",
    "def decision(probs):\n",
    "    if sum(probs>0.5)>0:\n",
    "        probs[probs > 0.5] = 1\n",
    "        probs[probs <= 0.5] = 0\n",
    "    else:\n",
    "        probs[probs == np.max(probs)] = 1\n",
    "        probs[probs != np.max(probs)] = 0\n",
    "    return probs\n",
    "\n",
    "occasion_result_df.apply(decision, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output occasion labels for each product\n",
    "\n",
    "occasion = []\n",
    "for i in occasion_result_df.index:\n",
    "    label = []\n",
    "    for j in occasion_result_df.columns:\n",
    "        if occasion_result_df.loc[i,j].any():\n",
    "            label.append(j)\n",
    "    occasion.append(label)\n",
    "occasion_result_df['Occasion'] = occasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cold weather</th>\n",
       "      <th>day to night</th>\n",
       "      <th>night out</th>\n",
       "      <th>vacation</th>\n",
       "      <th>weekend</th>\n",
       "      <th>work</th>\n",
       "      <th>workout</th>\n",
       "      <th>Occasion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[day to night]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[day to night, weekend, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[vacation, weekend]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cold weather  day to night  night out  vacation  weekend  work  workout  \\\n",
       "0           0.0           1.0        0.0       0.0      0.0   0.0      0.0   \n",
       "1           0.0           1.0        0.0       0.0      1.0   1.0      0.0   \n",
       "2           0.0           0.0        0.0       1.0      1.0   0.0      0.0   \n",
       "\n",
       "                        Occasion  \n",
       "0                 [day to night]  \n",
       "1  [day to night, weekend, work]  \n",
       "2            [vacation, weekend]  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occasion_result_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "occasion_final = occasion_result_df.loc[:,\"Occasion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Patterns/Prints - Jiayue (Daniel) Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null values with UNKNOWN_TOKEN\n",
    "df4['description'] = df4['description'].fillna('UNKNOWN_TOKEN')\n",
    "df4['details'] = df4['details'].fillna('UNKNOWN_TOKEN')\n",
    "df4['brand_category'] = df4['brand_category'].fillna('UNKNOWN_TOKEN')\n",
    "df4['details'] = df4['details'].str.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to remove punctuation\n",
    "def removePunctuation(text, punctuations=string.punctuation+\"``\"+\"’\"+\"”\"):\n",
    "    words=nltk.word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in punctuations]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText\n",
    "\n",
    "nltk_stopwords = set(stopwords.words(\"English\"))\n",
    "\n",
    "# define a function to remove stopwords\n",
    "def removeStopwords(text, stopwords=nltk_stopwords):\n",
    "    words = word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in stopwords]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText\n",
    "\n",
    "# define a function to lemmatize all texts\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(text)\n",
    "    lemmatizedWords = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "    lemmatizedText = \" \".join(lemmatizedWords)\n",
    "    return lemmatizedText\n",
    "\n",
    "columns = [\"brand\", \"product_full_name\", \"description\", \"details\"]\n",
    "for col in columns: \n",
    "    df4[col] = df4[col].apply(removePunctuation)\n",
    "    df4[col] = df4[col].apply(removeStopwords)\n",
    "    df4[col] = df4[col].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset[\"input_doc\"] = df4.brand+\" \"+df4.product_full_name+\" \"+df4.description+\" \"+df4.details\n",
    "subset['abstract'] = 0\n",
    "subset['animal'] = 0\n",
    "subset['camouflage'] = 0\n",
    "subset['colorblock'] = 0\n",
    "subset['dots'] = 0\n",
    "subset['floral'] = 0\n",
    "subset['geometric'] = 0\n",
    "subset['graphic'] = 0\n",
    "subset['houndstooth'] = 0\n",
    "subset['logo'] = 0\n",
    "subset['monogram'] = 0\n",
    "subset['multiprint'] = 0\n",
    "subset['paisley'] = 0\n",
    "subset['pinstripe'] = 0\n",
    "subset['plaid'] = 0\n",
    "subset['stripe'] = 0\n",
    "subset['stripehorizontal'] = 0\n",
    "subset['stripevertical'] = 0\n",
    "subset['tiedye'] = 0\n",
    "subset['tropical'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Modeling & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)\n",
    "\n",
    "def get_max_token_length_per_doc(docs):\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the complete pattern's file, we generate a list of max_length\n",
    "max_length_list = [150, 150, 124, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_values = list(subset.columns.values[1:,])\n",
    "for i in range(1, subset.shape[1]):\n",
    "    X_test = subset.iloc[:, 0].values\n",
    "    test_docs = list(X_test)\n",
    "    model = load_model(\"{}_model.h5\".format(pattern_values[i-1]))\n",
    "    with open('{}_tokenizer.pickle'.format(pattern_values[i-1]), 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "        \n",
    "   #predict\n",
    "    encoded_test_docs = integer_encode_documents(test_docs, tokenizer)\n",
    "    padded_test_docs = pad_sequences(encoded_test_docs, maxlen = max_length_list[i-1], padding = 'post')\n",
    "    prediction = model.predict(padded_test_docs, verbose = 0)\n",
    "    subset.iloc[:, i] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset.drop(['input_doc'], axis = 1)\n",
    "subset['patterns/prints'] = subset.idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>patterns/prints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>banana republic</td>\n",
       "      <td>ankle-strap pump</td>\n",
       "      <td>modern pump rounded silhouette ankle strap ext...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>modern pump rounded silhouette ankle strap ext...</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>banana republic</td>\n",
       "      <td>petite tie-neck top</td>\n",
       "      <td>dress jean sneaker dress tailored trouser heel...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>dress jean sneaker dress tailored trouser heel...</td>\n",
       "      <td>floral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>loewe</td>\n",
       "      <td>52mm padded leather round sunglass</td>\n",
       "      <td>padded leather cover classic round sunglass</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100 uv protection case cleaning cloth included...</td>\n",
       "      <td>logo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id            brand  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416  banana republic   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065  banana republic   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN            loewe   \n",
       "\n",
       "                    product_full_name  \\\n",
       "0                    ankle-strap pump   \n",
       "1                 petite tie-neck top   \n",
       "2  52mm padded leather round sunglass   \n",
       "\n",
       "                                         description  \\\n",
       "0  modern pump rounded silhouette ankle strap ext...   \n",
       "1  dress jean sneaker dress tailored trouser heel...   \n",
       "2        padded leather cover classic round sunglass   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "\n",
       "                                             details patterns/prints  \n",
       "0  modern pump rounded silhouette ankle strap ext...          animal  \n",
       "1  dress jean sneaker dress tailored trouser heel...          floral  \n",
       "2  100 uv protection case cleaning cloth included...            logo  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['patterns/prints'] = subset['patterns/prints']\n",
    "df4.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Category - Yuyao Shen \n",
    "\n",
    "According to Womens+Attributes.xlsx, general category has 6 attributes: top, bottom, onepiece, shoe, handbag and scarf. From tagged data, attributes include top, bottom, onepiece, shoe, sweater, accessory, blazer, hoodie etc. To combine these two categorization, I chose to keep top, bottom, onepiece, shoe, accessory only and blazer, sweater and hoodie are included in top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    use regular expression to clean text \n",
    "    replace numbers and units to variables\n",
    "    '''\n",
    "    p = re.compile(r'<.*?>')\n",
    "    text = p.sub('', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\xa0', '',text)\n",
    "    text = re.sub(r'\\d{1,3}(\\.|\\’)?\\d{1,3}?(\\\"|\\”)',\"length_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?%',\"percentage_val\", text)\n",
    "    text = text.strip(string.punctuation).replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?mm',\"mm_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?cm',\"cm_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?(inches|inch)',\"inches_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?(lbs|kg)',\"weight_val\", text)\n",
    "    text = re.sub(r'size\\s*?\\d{1,3}\\s*?',\"size_val\", text)\n",
    "    text = re.sub(r'\\b\\d+\\b',' ',text)\n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    mytokens = parser(text)\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "    return \" \".join(mytokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cate_test(inputFile):\n",
    "    '''\n",
    "    Input testing dataset that is going to be labeled\n",
    "    Keep relevant columns \n",
    "    Basic cleaning\n",
    "    Output cleaned testing dataset for category in a dataframe\n",
    "    '''\n",
    "    #full_test_data = pd.read_csv(inputFile)\n",
    "    full_test_data = df5  \n",
    "    ### keep relevant columns only\n",
    "    test_data = full_test_data[['product_full_name', 'details','description', 'brand_category']]\n",
    "    ### fill null values with 'Unknown_token'\n",
    "    test_data.fillna('Unknown_token', inplace = True)\n",
    "    X_test = test_data['product_full_name'] + ' '+ test_data['details'] + ' '+test_data['description']+ ' '+test_data['brand_category']\n",
    "    return test_data, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_classes(mat):\n",
    "    pred = list(map(lambda v: list(np.argsort(v))[-1:], mat))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data, X_test = clean_cate_test('full_data_final version.csv')\n",
    "X_test = X_test.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading vectorizer\n",
    "Pkl_Filename = \"category_token.pkl\"  \n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    tk = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "### vectorize incoming data\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "vector_text_test = tk.texts_to_sequences(X_test)\n",
    "padded_token_lists_test = pad_sequences(vector_text_test, maxlen=175, padding='post')\n",
    "X_test = pd.DataFrame(padded_token_lists_test, index = full_test_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3  Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading model\n",
    "Pkl_Filename = \"category_model.pkl\"  \n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use trained model to predict incoming data\n",
    "pred_vectors_test = model.predict(X_test)\n",
    "test_pred_classes = get_pred_classes(pred_vectors_test)\n",
    "categories = ['accessory', 'bottom', 'onepiece', 'shoe', 'top']\n",
    "cate_pred = [categories[i[0]] for i in test_pred_classes]\n",
    "predicted_test = pd.Series(cate_pred).str.capitalize() \n",
    "df5['category']  = list(predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Onepiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>Accessory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id            brand  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416  Banana Republic   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065  Banana Republic   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN            Loewe   \n",
       "\n",
       "                      product_full_name  \\\n",
       "0                      Ankle-Strap Pump   \n",
       "1                   Petite Tie-Neck Top   \n",
       "2  52MM Padded Leather Round Sunglasses   \n",
       "\n",
       "                                         description  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2    Padded leather covers classic round sunglasses.   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "\n",
       "                                             details   category  \n",
       "0  A modern pump, in a rounded silhouette with an...       Shoe  \n",
       "1  Dress it down with jeans and sneakers or dress...   Onepiece  \n",
       "2  100% UV protection Case and cleaning cloth inc...  Accessory  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['style'] = df1.style_prediction\n",
    "df['fit'] = df2.fit\n",
    "df['occasion'] = occasion_final\n",
    "df['patterns/prints'] = df4['patterns/prints']\n",
    "df['category'] = df5.category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the input is CSV, please change the file name below and run the last 3 cells, then the **df_full** will be the final output\n",
    "- If user input was used, no need to run the cells below, **df** is the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Please change the file name accordingly\n",
    "\n",
    "df_full = pd.read_csv('full_data_final version.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Append predicted tags to the orginal dataset\n",
    "\n",
    "df_full = df_full.merge(df, how = 'left',  on=['product_id', 'brand', 'product_full_name', 'description', \n",
    "                                     'brand_category', 'brand_canonical_url', 'details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "      <th>style</th>\n",
       "      <th>fit</th>\n",
       "      <th>occasion</th>\n",
       "      <th>patterns/prints</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>514683</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:37:15.719107+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[modern, businesscasual]</td>\n",
       "      <td>straightregular</td>\n",
       "      <td>[day to night]</td>\n",
       "      <td>animal</td>\n",
       "      <td>Shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>526676</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:36:50.682513+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[businesscasual, classic]</td>\n",
       "      <td>semifitted</td>\n",
       "      <td>[day to night, weekend, work]</td>\n",
       "      <td>floral</td>\n",
       "      <td>Onepiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>4.001E+11</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>2019-11-13 17:33:59.581661+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[casual, classic]</td>\n",
       "      <td>semifitted</td>\n",
       "      <td>[vacation, weekend]</td>\n",
       "      <td>logo</td>\n",
       "      <td>Accessory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>01DSJVKJNS6F4KQ1QM6YYK9AW2</td>\n",
       "      <td>Converse</td>\n",
       "      <td>4.00012E+11</td>\n",
       "      <td>Baby's &amp; Little Kid's All-Star Two-Tone Mid-To...</td>\n",
       "      <td>The iconic mid-top design gets an added dose o...</td>\n",
       "      <td>JustKids/Shoes/Baby024Months/BabyGirl,JustKids...</td>\n",
       "      <td>2019-11-13 17:05:05.203733+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/converse-babys...</td>\n",
       "      <td>Canvas upper Round toe Lace-up vamp SmartFOAM ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[classic, casual]</td>\n",
       "      <td>straightregular</td>\n",
       "      <td>[day to night, weekend]</td>\n",
       "      <td>logo</td>\n",
       "      <td>Shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>01DSK15ZD4D5A0QXA8NSD25YXE</td>\n",
       "      <td>Alexander McQueen</td>\n",
       "      <td>4.00011E+11</td>\n",
       "      <td>64MM Rimless Sunglasses</td>\n",
       "      <td>Hexagonal shades offer a rimless view with int...</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval</td>\n",
       "      <td>2019-11-13 18:42:30.941321+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/alexander-mcqu...</td>\n",
       "      <td>100% UV protection Gradient lenses Adjustable ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[casual, modern]</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>[weekend]</td>\n",
       "      <td>animal</td>\n",
       "      <td>Accessory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48974</td>\n",
       "      <td>01DSNVXY8EJ9FQAJ3MPDMPASHD</td>\n",
       "      <td>Bonpoint</td>\n",
       "      <td>4.00091E+11</td>\n",
       "      <td>Baby's Hooded Jacket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JustKids/Baby024months/InfantGirls/Outerwear</td>\n",
       "      <td>2019-11-14 21:08:28.040417+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/bonpoint-babys...</td>\n",
       "      <td>Cozy double breasted jacket crafted from cotto...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[classic, casual]</td>\n",
       "      <td>oversized</td>\n",
       "      <td>[cold weather, day to night, weekend]</td>\n",
       "      <td>logo</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48975</td>\n",
       "      <td>01DSGYHA3RMCHENBJVQPBGXM97</td>\n",
       "      <td>Laura Mercier</td>\n",
       "      <td>4.00096E+11</td>\n",
       "      <td>Flawless Fusion Ultra-Longwear Foundation</td>\n",
       "      <td>WHAT IT ISA 15-hour long wearing, water resist...</td>\n",
       "      <td>SaksBeautyPlace/ForHer/Color/Foundation/Liquid...</td>\n",
       "      <td>2019-11-12 23:17:47.761072+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/laura-mercier-...</td>\n",
       "      <td>WHAT IT ISA 15-hour long wearing, water resist...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[casual, androgynous]</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>[vacation, weekend]</td>\n",
       "      <td>logo</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48976</td>\n",
       "      <td>01DSJT8H12CAFQQH07SQSQWJ8C</td>\n",
       "      <td>Splendid</td>\n",
       "      <td>4.001E+11</td>\n",
       "      <td>Baby Girl's 2-Piece Ruffle Sweatshirt &amp; Stripe...</td>\n",
       "      <td>Ruffled-trim sweatshirt lends romance to this ...</td>\n",
       "      <td>JustKids/Baby024months/InfantGirls/Tops,JustKi...</td>\n",
       "      <td>2019-11-13 16:41:34.491443+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/splendid-baby-...</td>\n",
       "      <td>Crewneck Long sleeves Rib-knit neck, cuffs and...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[classic, casual]</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>[day to night, weekend]</td>\n",
       "      <td>stripevertical</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48977</td>\n",
       "      <td>01DSH2PF9J7QZ44D842B3GMCFN</td>\n",
       "      <td>Florence Eiseman</td>\n",
       "      <td>4.00012E+11</td>\n",
       "      <td>Little Girl's Plaid &amp; Velvet Dress</td>\n",
       "      <td>Pretty plaid dress with velvet collar and velv...</td>\n",
       "      <td>JustKids/Girls214/ToddlerGirls24/Dresses,JustK...</td>\n",
       "      <td>2019-11-13 00:30:31.212215+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/florence-eisem...</td>\n",
       "      <td>Peter Pan collar Short sleeves Back zipper Two...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[modern, casual]</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>[weekend]</td>\n",
       "      <td>plaid</td>\n",
       "      <td>Onepiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48978</td>\n",
       "      <td>01DSH54D3PWHKFZK5A8A2JE3RQ</td>\n",
       "      <td>Gucci</td>\n",
       "      <td>4.00011E+11</td>\n",
       "      <td>Baby Girl's Short-Sleeve Dress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JustKids/Baby024months/InfantGirls/Dresses</td>\n",
       "      <td>2019-11-13 01:13:04.880787+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/gucci-baby-gir...</td>\n",
       "      <td>Corduroy dress with bow Cotton corduroy Web gr...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[casual, classic]</td>\n",
       "      <td>semifitted</td>\n",
       "      <td>[weekend]</td>\n",
       "      <td>animal</td>\n",
       "      <td>Bottom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48979 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       product_id              brand          mpn  \\\n",
       "0      01DSE9TC2DQXDG6GWKW9NMJ416    Banana Republic       514683   \n",
       "1      01DSE9SKM19XNA6SJP36JZC065    Banana Republic       526676   \n",
       "2      01DSJX8GD4DSAP76SPR85HRCMN              Loewe    4.001E+11   \n",
       "3      01DSJVKJNS6F4KQ1QM6YYK9AW2           Converse  4.00012E+11   \n",
       "4      01DSK15ZD4D5A0QXA8NSD25YXE  Alexander McQueen  4.00011E+11   \n",
       "...                           ...                ...          ...   \n",
       "48974  01DSNVXY8EJ9FQAJ3MPDMPASHD           Bonpoint  4.00091E+11   \n",
       "48975  01DSGYHA3RMCHENBJVQPBGXM97      Laura Mercier  4.00096E+11   \n",
       "48976  01DSJT8H12CAFQQH07SQSQWJ8C           Splendid    4.001E+11   \n",
       "48977  01DSH2PF9J7QZ44D842B3GMCFN   Florence Eiseman  4.00012E+11   \n",
       "48978  01DSH54D3PWHKFZK5A8A2JE3RQ              Gucci  4.00011E+11   \n",
       "\n",
       "                                       product_full_name  \\\n",
       "0                                       Ankle-Strap Pump   \n",
       "1                                    Petite Tie-Neck Top   \n",
       "2                   52MM Padded Leather Round Sunglasses   \n",
       "3      Baby's & Little Kid's All-Star Two-Tone Mid-To...   \n",
       "4                                64MM Rimless Sunglasses   \n",
       "...                                                  ...   \n",
       "48974                               Baby's Hooded Jacket   \n",
       "48975          Flawless Fusion Ultra-Longwear Foundation   \n",
       "48976  Baby Girl's 2-Piece Ruffle Sweatshirt & Stripe...   \n",
       "48977                 Little Girl's Plaid & Velvet Dress   \n",
       "48978                     Baby Girl's Short-Sleeve Dress   \n",
       "\n",
       "                                             description  \\\n",
       "0      A modern pump, in a rounded silhouette with an...   \n",
       "1      Dress it down with jeans and sneakers or dress...   \n",
       "2        Padded leather covers classic round sunglasses.   \n",
       "3      The iconic mid-top design gets an added dose o...   \n",
       "4      Hexagonal shades offer a rimless view with int...   \n",
       "...                                                  ...   \n",
       "48974                                                NaN   \n",
       "48975  WHAT IT ISA 15-hour long wearing, water resist...   \n",
       "48976  Ruffled-trim sweatshirt lends romance to this ...   \n",
       "48977  Pretty plaid dress with velvet collar and velv...   \n",
       "48978                                                NaN   \n",
       "\n",
       "                                          brand_category  \\\n",
       "0                                                Unknown   \n",
       "1                                                Unknown   \n",
       "2      JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "3      JustKids/Shoes/Baby024Months/BabyGirl,JustKids...   \n",
       "4         JewelryAccessories/SunglassesReaders/RoundOval   \n",
       "...                                                  ...   \n",
       "48974       JustKids/Baby024months/InfantGirls/Outerwear   \n",
       "48975  SaksBeautyPlace/ForHer/Color/Foundation/Liquid...   \n",
       "48976  JustKids/Baby024months/InfantGirls/Tops,JustKi...   \n",
       "48977  JustKids/Girls214/ToddlerGirls24/Dresses,JustK...   \n",
       "48978         JustKids/Baby024months/InfantGirls/Dresses   \n",
       "\n",
       "                          created_at                     updated_at  \\\n",
       "0      2019-11-11 22:37:15.719107+00  2019-12-19 20:40:30.786144+00   \n",
       "1      2019-11-11 22:36:50.682513+00  2019-12-19 20:40:30.786144+00   \n",
       "2      2019-11-13 17:33:59.581661+00  2019-12-19 20:40:30.786144+00   \n",
       "3      2019-11-13 17:05:05.203733+00  2019-12-19 20:40:30.786144+00   \n",
       "4      2019-11-13 18:42:30.941321+00  2019-12-19 20:40:30.786144+00   \n",
       "...                              ...                            ...   \n",
       "48974  2019-11-14 21:08:28.040417+00  2019-12-19 20:40:30.786144+00   \n",
       "48975  2019-11-12 23:17:47.761072+00  2019-12-19 20:40:30.786144+00   \n",
       "48976  2019-11-13 16:41:34.491443+00  2019-12-19 20:40:30.786144+00   \n",
       "48977  2019-11-13 00:30:31.212215+00  2019-12-19 20:40:30.786144+00   \n",
       "48978  2019-11-13 01:13:04.880787+00  2019-12-19 20:40:30.786144+00   \n",
       "\n",
       "      deleted_at                                brand_canonical_url  \\\n",
       "0            NaN  https://bananarepublic.gap.com/browse/product....   \n",
       "1            NaN  https://bananarepublic.gap.com/browse/product....   \n",
       "2            NaN  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "3            NaN  https://www.saksfifthavenue.com/converse-babys...   \n",
       "4            NaN  https://www.saksfifthavenue.com/alexander-mcqu...   \n",
       "...          ...                                                ...   \n",
       "48974        NaN  https://www.saksfifthavenue.com/bonpoint-babys...   \n",
       "48975        NaN  https://www.saksfifthavenue.com/laura-mercier-...   \n",
       "48976        NaN  https://www.saksfifthavenue.com/splendid-baby-...   \n",
       "48977        NaN  https://www.saksfifthavenue.com/florence-eisem...   \n",
       "48978        NaN  https://www.saksfifthavenue.com/gucci-baby-gir...   \n",
       "\n",
       "                                                 details            labels  \\\n",
       "0      A modern pump, in a rounded silhouette with an...  {\"Needs Review\"}   \n",
       "1      Dress it down with jeans and sneakers or dress...  {\"Needs Review\"}   \n",
       "2      100% UV protection Case and cleaning cloth inc...  {\"Needs Review\"}   \n",
       "3      Canvas upper Round toe Lace-up vamp SmartFOAM ...  {\"Needs Review\"}   \n",
       "4      100% UV protection Gradient lenses Adjustable ...  {\"Needs Review\"}   \n",
       "...                                                  ...               ...   \n",
       "48974  Cozy double breasted jacket crafted from cotto...  {\"Needs Review\"}   \n",
       "48975  WHAT IT ISA 15-hour long wearing, water resist...  {\"Needs Review\"}   \n",
       "48976  Crewneck Long sleeves Rib-knit neck, cuffs and...  {\"Needs Review\"}   \n",
       "48977  Peter Pan collar Short sleeves Back zipper Two...  {\"Needs Review\"}   \n",
       "48978  Corduroy dress with bow Cotton corduroy Web gr...  {\"Needs Review\"}   \n",
       "\n",
       "       bc_product_id                      style              fit  \\\n",
       "0                NaN   [modern, businesscasual]  straightregular   \n",
       "1                NaN  [businesscasual, classic]       semifitted   \n",
       "2                NaN          [casual, classic]       semifitted   \n",
       "3                NaN          [classic, casual]  straightregular   \n",
       "4                NaN           [casual, modern]          relaxed   \n",
       "...              ...                        ...              ...   \n",
       "48974            NaN          [classic, casual]        oversized   \n",
       "48975            NaN      [casual, androgynous]          relaxed   \n",
       "48976            NaN          [classic, casual]          relaxed   \n",
       "48977            NaN           [modern, casual]          relaxed   \n",
       "48978            NaN          [casual, classic]       semifitted   \n",
       "\n",
       "                                    occasion patterns/prints   category  \n",
       "0                             [day to night]          animal       Shoe  \n",
       "1              [day to night, weekend, work]          floral   Onepiece  \n",
       "2                        [vacation, weekend]            logo  Accessory  \n",
       "3                    [day to night, weekend]            logo       Shoe  \n",
       "4                                  [weekend]          animal  Accessory  \n",
       "...                                      ...             ...        ...  \n",
       "48974  [cold weather, day to night, weekend]            logo        Top  \n",
       "48975                    [vacation, weekend]            logo        Top  \n",
       "48976                [day to night, weekend]  stripevertical        Top  \n",
       "48977                              [weekend]           plaid   Onepiece  \n",
       "48978                              [weekend]          animal     Bottom  \n",
       "\n",
       "[48979 rows x 18 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
