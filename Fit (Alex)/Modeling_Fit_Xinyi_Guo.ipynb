{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the codes I wrote for DSO 560 Text Analytics & NLP Final Project to predict **fit** for women clothing. The client is ThreadTogether, an Australian Non-profit orgnazation.\n",
    "- Part I focuses on data preprocessing and model building \n",
    "- Part II is the final prediction program. The main() function will ask user for a CSV file input and output a CSV file with an additional fit column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create on: 5.2.2020\n",
    "\n",
    "Create by: Xinyi (Alex) Guo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.models import load_model\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "startTime = pd.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing and Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "- The full data and tagged attribute data was merged in Postico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedData = pd.read_csv(\"merged_data_159k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159013, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "      <th>product_id.1</th>\n",
       "      <th>product_color_id</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DPGV4YRP3Z8J85DASGZ1Y99W</td>\n",
       "      <td>Frame</td>\n",
       "      <td>LWAX0056</td>\n",
       "      <td>Les Second - Medium--NOIR</td>\n",
       "      <td>Minimal, Modern Styling Meets Refined Luxury I...</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2019-10-06 15:31:31.730524+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://frame-store.com/products/les-second-me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01DPGV4YRP3Z8J85DASGZ1Y99W</td>\n",
       "      <td>01DPGVGBK6YGNYGNF2S6FSH02T</td>\n",
       "      <td>style</td>\n",
       "      <td>Casual</td>\n",
       "      <td>initial_tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DPGV4YRP3Z8J85DASGZ1Y99W</td>\n",
       "      <td>Frame</td>\n",
       "      <td>LWAX0056</td>\n",
       "      <td>Les Second - Medium--NOIR</td>\n",
       "      <td>Minimal, Modern Styling Meets Refined Luxury I...</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2019-10-06 15:31:31.730000+00:00</td>\n",
       "      <td>2020-04-06 23:19:53.216000+00:00</td>\n",
       "      <td>2020-04-06 23:19:53.216000+00:00</td>\n",
       "      <td>https://frame-store.com/products/les-second-me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>185.0</td>\n",
       "      <td>01DPGV4YRP3Z8J85DASGZ1Y99W</td>\n",
       "      <td>01DPGVGBK6YGNYGNF2S6FSH02T</td>\n",
       "      <td>style</td>\n",
       "      <td>Casual</td>\n",
       "      <td>initial_tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DSE8Z2ZDAZKZ2SKCS1E3B3HK</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>491075</td>\n",
       "      <td>Madison 12-Hour Loafer Pump</td>\n",
       "      <td>Everything you love about our original Madison...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:22:21.664000+00:00</td>\n",
       "      <td>2020-03-25 23:24:44.823000+00:00</td>\n",
       "      <td>2020-03-23 21:06:15.953000+00:00</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Everything you love about our original Madison...</td>\n",
       "      <td>[]</td>\n",
       "      <td>431.0</td>\n",
       "      <td>01DSE8Z2ZDAZKZ2SKCS1E3B3HK</td>\n",
       "      <td>01DSE8ZG8Y3FR8KWE2TY1QDWBF</td>\n",
       "      <td>shoe_width</td>\n",
       "      <td>Medium</td>\n",
       "      <td>initial_tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DSE8Z2ZDAZKZ2SKCS1E3B3HK</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>491075</td>\n",
       "      <td>Madison 12-Hour Loafer Pump</td>\n",
       "      <td>Everything you love about our original Madison...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:22:21.664425+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Everything you love about our original Madison...</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01DSE8Z2ZDAZKZ2SKCS1E3B3HK</td>\n",
       "      <td>01DSE8ZG8Y3FR8KWE2TY1QDWBF</td>\n",
       "      <td>shoe_width</td>\n",
       "      <td>Medium</td>\n",
       "      <td>initial_tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01E2C3YN4KQ36A0REWZJ89ZN73</td>\n",
       "      <td>FREDA SALVADOR</td>\n",
       "      <td>5229129</td>\n",
       "      <td>Ace Bootie</td>\n",
       "      <td>Edgy style and expert craftsmanship combine on...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2020-03-01 22:37:32.169000+00:00</td>\n",
       "      <td>2020-04-15 21:46:03.512000+00:00</td>\n",
       "      <td>2020-03-18 23:00:31.558000+00:00</td>\n",
       "      <td>https://shop.nordstrom.com/s/freda-salvador-ac...</td>\n",
       "      <td>True to size. 2 1/4\" (57mm) heel (size 8.5) 5\"...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>01E2C3YN4KQ36A0REWZJ89ZN73</td>\n",
       "      <td>01E2C3YN56ZCJ8TN45V3EC8CPS</td>\n",
       "      <td>Primary Color</td>\n",
       "      <td>Blacks</td>\n",
       "      <td>initial_tags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id            brand       mpn  \\\n",
       "0  01DPGV4YRP3Z8J85DASGZ1Y99W            Frame  LWAX0056   \n",
       "1  01DPGV4YRP3Z8J85DASGZ1Y99W            Frame  LWAX0056   \n",
       "2  01DSE8Z2ZDAZKZ2SKCS1E3B3HK  Banana Republic    491075   \n",
       "3  01DSE8Z2ZDAZKZ2SKCS1E3B3HK  Banana Republic    491075   \n",
       "4  01E2C3YN4KQ36A0REWZJ89ZN73   FREDA SALVADOR   5229129   \n",
       "\n",
       "             product_full_name  \\\n",
       "0    Les Second - Medium--NOIR   \n",
       "1    Les Second - Medium--NOIR   \n",
       "2  Madison 12-Hour Loafer Pump   \n",
       "3  Madison 12-Hour Loafer Pump   \n",
       "4                   Ace Bootie   \n",
       "\n",
       "                                         description brand_category  \\\n",
       "0  Minimal, Modern Styling Meets Refined Luxury I...    Accessories   \n",
       "1  Minimal, Modern Styling Meets Refined Luxury I...    Accessories   \n",
       "2  Everything you love about our original Madison...        Unknown   \n",
       "3  Everything you love about our original Madison...        Unknown   \n",
       "4  Edgy style and expert craftsmanship combine on...        Unknown   \n",
       "\n",
       "                         created_at                        updated_at  \\\n",
       "0     2019-10-06 15:31:31.730524+00     2019-12-19 20:40:30.786144+00   \n",
       "1  2019-10-06 15:31:31.730000+00:00  2020-04-06 23:19:53.216000+00:00   \n",
       "2  2019-11-11 22:22:21.664000+00:00  2020-03-25 23:24:44.823000+00:00   \n",
       "3     2019-11-11 22:22:21.664425+00     2019-12-19 20:40:30.786144+00   \n",
       "4  2020-03-01 22:37:32.169000+00:00  2020-04-15 21:46:03.512000+00:00   \n",
       "\n",
       "                         deleted_at  \\\n",
       "0                               NaN   \n",
       "1  2020-04-06 23:19:53.216000+00:00   \n",
       "2  2020-03-23 21:06:15.953000+00:00   \n",
       "3                               NaN   \n",
       "4  2020-03-18 23:00:31.558000+00:00   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://frame-store.com/products/les-second-me...   \n",
       "1  https://frame-store.com/products/les-second-me...   \n",
       "2  https://bananarepublic.gap.com/browse/product....   \n",
       "3  https://bananarepublic.gap.com/browse/product....   \n",
       "4  https://shop.nordstrom.com/s/freda-salvador-ac...   \n",
       "\n",
       "                                             details labels  bc_product_id  \\\n",
       "0                                                NaN     {}            NaN   \n",
       "1                                                NaN     []          185.0   \n",
       "2  Everything you love about our original Madison...     []          431.0   \n",
       "3  Everything you love about our original Madison...     {}            NaN   \n",
       "4  True to size. 2 1/4\" (57mm) heel (size 8.5) 5\"...     []         1051.0   \n",
       "\n",
       "                 product_id.1            product_color_id attribute_name  \\\n",
       "0  01DPGV4YRP3Z8J85DASGZ1Y99W  01DPGVGBK6YGNYGNF2S6FSH02T          style   \n",
       "1  01DPGV4YRP3Z8J85DASGZ1Y99W  01DPGVGBK6YGNYGNF2S6FSH02T          style   \n",
       "2  01DSE8Z2ZDAZKZ2SKCS1E3B3HK  01DSE8ZG8Y3FR8KWE2TY1QDWBF     shoe_width   \n",
       "3  01DSE8Z2ZDAZKZ2SKCS1E3B3HK  01DSE8ZG8Y3FR8KWE2TY1QDWBF     shoe_width   \n",
       "4  01E2C3YN4KQ36A0REWZJ89ZN73  01E2C3YN56ZCJ8TN45V3EC8CPS  Primary Color   \n",
       "\n",
       "  attribute_value          file  \n",
       "0          Casual  initial_tags  \n",
       "1          Casual  initial_tags  \n",
       "2          Medium  initial_tags  \n",
       "3          Medium  initial_tags  \n",
       "4          Blacks  initial_tags  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159013 entries, 0 to 159012\n",
      "Data columns (total 18 columns):\n",
      "product_id             159013 non-null object\n",
      "brand                  159013 non-null object\n",
      "mpn                    159013 non-null object\n",
      "product_full_name      159013 non-null object\n",
      "description            148089 non-null object\n",
      "brand_category         153172 non-null object\n",
      "created_at             159013 non-null object\n",
      "updated_at             159013 non-null object\n",
      "deleted_at             108946 non-null object\n",
      "brand_canonical_url    158979 non-null object\n",
      "details                133971 non-null object\n",
      "labels                 159013 non-null object\n",
      "bc_product_id          120574 non-null float64\n",
      "product_id.1           159013 non-null object\n",
      "product_color_id       159013 non-null object\n",
      "attribute_name         159013 non-null object\n",
      "attribute_value        159013 non-null object\n",
      "file                   159013 non-null object\n",
      "dtypes: float64(1), object(17)\n",
      "memory usage: 21.8+ MB\n"
     ]
    }
   ],
   "source": [
    "mergedData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df = mergedData[mergedData.attribute_name == 'fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6361, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df.reset_index(inplace = True)\n",
    "fit_df = fit_df.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "fit_df.drop_duplicates('product_color_id', keep = 'last', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3686, 18)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id               0\n",
       "brand                    0\n",
       "mpn                      0\n",
       "product_full_name        0\n",
       "description            325\n",
       "brand_category         338\n",
       "created_at               0\n",
       "updated_at               0\n",
       "deleted_at             536\n",
       "brand_canonical_url      0\n",
       "details                303\n",
       "labels                   0\n",
       "bc_product_id          323\n",
       "product_id.1             0\n",
       "product_color_id         0\n",
       "attribute_name           0\n",
       "attribute_value          0\n",
       "file                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to remove punctuation\n",
    "import string \n",
    "def removePunctuation(text, punctuations=string.punctuation+\"``\"+\"’\"+\"”\"):\n",
    "    words=nltk.word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in punctuations]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = set(stopwords.words(\"English\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to remove stopwords\n",
    "def removeStopwords(text, stopwords=nltk_stopwords):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in stopwords]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for lemmatization\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatizedWords = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "    lemmatizedText = \" \".join(lemmatizedWords)\n",
    "    return lemmatizedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy variables for each fit category\n",
    "dummies = pd.get_dummies(fit_df['attribute_value'])\n",
    "fit_df = pd.concat([fit_df, dummies], axis = 1)\n",
    "fit_df.reset_index(inplace = True)\n",
    "fit_df = fit_df.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, columns = [\"brand\", \"product_full_name\", \"description\", \"details\"]):\n",
    "    df['details'] = df['details'].str.replace(\"\\n\", \"\")\n",
    "    #replace null values with UNKNOWN_TOKEN\n",
    "    df['brand'] = df['brand'].fillna('UNKNOWN_TOKEN')\n",
    "    df['description'] = df['description'].fillna('UNKNOWN_TOKEN')\n",
    "    df['details'] = df['details'].fillna('UNKNOWN_TOKEN')\n",
    "    df['product_full_name'] = df['product_full_name'].fillna('UNKNOWN_TOKEN')\n",
    "    #remove punctuation and stopwords then lemmatize\n",
    "    for col in columns: \n",
    "        df[col] = df[col].apply(removePunctuation)\n",
    "        df[col] = df[col].apply(removeStopwords)\n",
    "        df[col] = df[col].apply(lemmatize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df = preprocessing(fit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToDrop = ['mpn', 'created_at', 'updated_at', 'brand_category', 'deleted_at','product_id.1', 'bc_product_id', 'labels', 'attribute_name', 'file']\n",
    "fit_df = fit_df.drop(columnsToDrop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df[\"input_doc\"] = fit_df.brand + \" \" + fit_df.product_full_name + \" \" + fit_df.description + \" \" + fit_df.details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id             0\n",
       "brand                  0\n",
       "product_full_name      0\n",
       "description            0\n",
       "brand_canonical_url    0\n",
       "details                0\n",
       "product_color_id       0\n",
       "attribute_value        0\n",
       "fittedtailored         0\n",
       "oversized              0\n",
       "relaxed                0\n",
       "semifitted             0\n",
       "straightregular        0\n",
       "input_doc              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3686, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Keras Deep Learning Model\n",
    "- During this step, I trained and test out the Keras model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_token_length_per_doc(docs):\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(df, target, EMBEDDING_SIZE = 100):\n",
    "    X = df.loc[:, \"input_doc\"].values\n",
    "    y = df.loc[:, target].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n",
    "    docs = list(X_train)\n",
    "    labels = y_train\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(docs)\n",
    "    vocab_size = len(tokenizer.word_index) + 1 \n",
    "    # integer encode the documentsa\n",
    "    encoded_docs = integer_encode_documents(docs, tokenizer)\n",
    "    # get the max length in terms of token length\n",
    "    max_length = get_max_token_length_per_doc(docs)\n",
    "    # pad documents to a max length of words\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length=max_length))\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    # fit the model\n",
    "    model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "    # evaluate the model\n",
    "    loss, trainingAccuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "    \n",
    "    #testing\n",
    "    test_docs = list(X_test)\n",
    "    test_labels = y_test\n",
    "    encoded_test_docs = integer_encode_documents(test_docs, tokenizer)\n",
    "    padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "    loss, testAccuracy = model.evaluate(padded_test_docs, test_labels, verbose=0)\n",
    "    prediction_proba = model.predict(padded_test_docs, verbose = 0)\n",
    "    \n",
    "    score_dict = {\"target\": target, \"trainingAccuracy\": round(trainingAccuracy, 2), \n",
    "                  \"testAccuracy\": round(testAccuracy,2)}\n",
    "    \n",
    "    return score_dict, prediction_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "straightregular prediction done\n",
      "semifitted prediction done\n",
      "relaxed prediction done\n",
      "oversized prediction done\n",
      "fittedtailored prediction done\n"
     ]
    }
   ],
   "source": [
    "#Predict for each fit type \n",
    "fitType = list(fit_df.attribute_value.unique())\n",
    "scoreList = []\n",
    "prob_df = pd.DataFrame()\n",
    "for fit in fitType:\n",
    "    score_dict, prediction_proba = prediction(fit_df, target = fit)\n",
    "    scoreList.append(score_dict)\n",
    "    prob_df[fit] = prediction_proba.flatten()\n",
    "    print(fit, \"prediction done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and testing accuracy\n",
    "score_df = pd.DataFrame(scoreList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>trainingAccuracy</th>\n",
       "      <th>testAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>straightregular</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>semifitted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oversized</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fittedtailored</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  trainingAccuracy  testAccuracy\n",
       "0  straightregular               1.0          0.91\n",
       "1       semifitted               1.0          0.84\n",
       "2          relaxed               1.0          0.81\n",
       "3        oversized               1.0          0.97\n",
       "4   fittedtailored               1.0          0.93"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the fit with the highest probability out of the 5 fit categories\n",
    "prob_df['predict_fit'] = prob_df.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>straightregular</th>\n",
       "      <th>semifitted</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>oversized</th>\n",
       "      <th>fittedtailored</th>\n",
       "      <th>predict_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.408755</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.106553</td>\n",
       "      <td>5.602837e-06</td>\n",
       "      <td>9.595108e-01</td>\n",
       "      <td>fittedtailored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.008466</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>4.380941e-05</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.042026</td>\n",
       "      <td>0.947667</td>\n",
       "      <td>4.172325e-07</td>\n",
       "      <td>3.181696e-04</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.952116</td>\n",
       "      <td>9.179115e-06</td>\n",
       "      <td>1.043081e-06</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.998580</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>8.642673e-07</td>\n",
       "      <td>1.490116e-07</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>3.087223e-04</td>\n",
       "      <td>1.391259e-02</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.920671</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>5.862117e-05</td>\n",
       "      <td>8.940697e-08</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011393</td>\n",
       "      <td>8.940697e-08</td>\n",
       "      <td>3.546476e-06</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>1.556547e-05</td>\n",
       "      <td>8.845456e-04</td>\n",
       "      <td>straightregular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.041249</td>\n",
       "      <td>3.456180e-05</td>\n",
       "      <td>3.834261e-06</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     straightregular  semifitted   relaxed     oversized  fittedtailored  \\\n",
       "0           0.408755    0.000096  0.106553  5.602837e-06    9.595108e-01   \n",
       "1           0.000038    0.008466  0.000012  4.380941e-05    5.960464e-08   \n",
       "2           0.000034    0.042026  0.947667  4.172325e-07    3.181696e-04   \n",
       "3           0.000794    0.000487  0.952116  9.179115e-06    1.043081e-06   \n",
       "4           0.000057    0.998580  0.000108  8.642673e-07    1.490116e-07   \n",
       "..               ...         ...       ...           ...             ...   \n",
       "917         0.000013    0.000041  0.897436  3.087223e-04    1.391259e-02   \n",
       "918         0.003296    0.920671  0.000728  5.862117e-05    8.940697e-08   \n",
       "919         0.000013    0.000000  0.011393  8.940697e-08    3.546476e-06   \n",
       "920         0.999871    0.014819  0.000656  1.556547e-05    8.845456e-04   \n",
       "921         0.000247    0.000232  0.041249  3.456180e-05    3.834261e-06   \n",
       "\n",
       "         predict_fit  \n",
       "0     fittedtailored  \n",
       "1         semifitted  \n",
       "2            relaxed  \n",
       "3            relaxed  \n",
       "4         semifitted  \n",
       "..               ...  \n",
       "917          relaxed  \n",
       "918       semifitted  \n",
       "919          relaxed  \n",
       "920  straightregular  \n",
       "921          relaxed  \n",
       "\n",
       "[922 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Keras Model & build automated prediction\n",
    "- Since the Keras model had high accuracy of 80 - 90%, I decided to save my models and tokenizers. I did training and testing prediction again with the same random state to ensure my code is correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTestData(df, target):\n",
    "    X = fit_df.loc[:, [\"brand\", \"product_full_name\", \"description\", \"details\"]]\n",
    "    y = fit_df.loc[:, target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n",
    "    X_test.to_csv(\"x_test_{}.csv\".format(target))\n",
    "    pd.DataFrame(y_test).to_csv(\"y_test_{}.csv\".format(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['straightregular', 'semifitted', 'relaxed', 'oversized', 'fittedtailored']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitType = list(fit_df.attribute_value.unique())\n",
    "fitType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fit in fitType:\n",
    "    generateTestData(fit_df, target = fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildKerasModel(df, target, EMBEDDING_SIZE = 100):\n",
    "    X = df.loc[:, \"input_doc\"].values\n",
    "    y = df.loc[:, target].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n",
    "    docs = list(X_train)\n",
    "    labels = y_train\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(docs)\n",
    "    vocab_size = len(tokenizer.word_index) + 1 \n",
    "    # integer encode the documentsa\n",
    "    encoded_docs = integer_encode_documents(docs, tokenizer)\n",
    "    # get the max length in terms of token length\n",
    "    max_length = get_max_token_length_per_doc(docs)\n",
    "    # pad documents to a max length of words\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length=max_length))\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    # fit the model\n",
    "    model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "    # evaluate the model\n",
    "    loss, trainingAccuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "    \n",
    "    #save model\n",
    "    model.save(\"{}_model.h5\".format(target))\n",
    "    \n",
    "    \n",
    "    #save tokenizer\n",
    "    with open('{}_tokenizer.pickle'.format(target), 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "straightregular done\n",
      "semifitted done\n",
      "relaxed done\n",
      "oversized done\n",
      "fittedtailored done\n"
     ]
    }
   ],
   "source": [
    "maxLengthDict = {}\n",
    "for fit in fitType:\n",
    "    maxLengthDict[fit] = buildKerasModel(df = fit_df, target = fit, EMBEDDING_SIZE = 100)\n",
    "    print(fit, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(input_X_test_file, input_y_test_file, target, max_length):\n",
    "    #load data\n",
    "    X_test_df = pd.read_csv(input_X_test_file, index_col = 0)\n",
    "    X_test_df[\"input_doc\"] = X_test_df.brand + \" \" + X_test_df.product_full_name + \" \" + X_test_df.description + \" \" + X_test_df.details \n",
    "    X_test = X_test_df.loc[:, \"input_doc\"].values\n",
    "    y_test_df = pd.read_csv(input_y_test_file, index_col = 0)\n",
    "    y_test = y_test_df.loc[:, target].values\n",
    "    test_docs = list(X_test)\n",
    "    test_labels = y_test\n",
    "    \n",
    "    #load model\n",
    "    model = load_model(\"{}_model.h5\".format(target))\n",
    "    with open('{}_tokenizer.pickle'.format(target), 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "        \n",
    "    #predict\n",
    "    encoded_test_docs = integer_encode_documents(test_docs, tokenizer)\n",
    "    padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "    loss, testAccuracy = model.evaluate(padded_test_docs, test_labels, verbose=0)\n",
    "    prediction_proba = model.predict(padded_test_docs, verbose = 0)\n",
    "\n",
    "    score_dict = {\"target\": target, \"testAccuracy\": round(testAccuracy,2)}\n",
    "    \n",
    "    return score_dict, prediction_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'straightregular': 185,\n",
       " 'semifitted': 185,\n",
       " 'relaxed': 202,\n",
       " 'oversized': 202,\n",
       " 'fittedtailored': 202}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxLengthDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "straightregular done\n",
      "semifitted done\n",
      "relaxed done\n",
      "oversized done\n",
      "fittedtailored done\n"
     ]
    }
   ],
   "source": [
    "scoreList = []\n",
    "prob_df = pd.DataFrame()\n",
    "for fit in fitType:\n",
    "    input_X_test_file = \"x_test_{}.csv\".format(fit)\n",
    "    input_y_test_file = \"y_test_{}.csv\".format(fit)\n",
    "    score_dict, prediction_proba = test(input_X_test_file,input_y_test_file, target = fit, max_length = maxLengthDict[fit])\n",
    "    scoreList.append(score_dict)\n",
    "    prob_df[fit] = prediction_proba.flatten()\n",
    "    print(fit, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(scoreList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>testAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>straightregular</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>semifitted</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oversized</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fittedtailored</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  testAccuracy\n",
       "0  straightregular          0.91\n",
       "1       semifitted          0.84\n",
       "2          relaxed          0.81\n",
       "3        oversized          0.97\n",
       "4   fittedtailored          0.93"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df['predict_fit'] = prob_df.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>straightregular</th>\n",
       "      <th>semifitted</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>oversized</th>\n",
       "      <th>fittedtailored</th>\n",
       "      <th>predict_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.466508</td>\n",
       "      <td>1.281500e-04</td>\n",
       "      <td>0.065370</td>\n",
       "      <td>2.604723e-05</td>\n",
       "      <td>9.627302e-01</td>\n",
       "      <td>fittedtailored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000039</td>\n",
       "      <td>4.094937e-02</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>5.698204e-05</td>\n",
       "      <td>2.086163e-07</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>1.686387e-01</td>\n",
       "      <td>0.983514</td>\n",
       "      <td>1.788139e-07</td>\n",
       "      <td>7.907152e-04</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000819</td>\n",
       "      <td>2.659559e-04</td>\n",
       "      <td>0.767777</td>\n",
       "      <td>1.189113e-05</td>\n",
       "      <td>4.231930e-06</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000077</td>\n",
       "      <td>9.986877e-01</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>7.748604e-07</td>\n",
       "      <td>7.152557e-07</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>3.337860e-05</td>\n",
       "      <td>0.889967</td>\n",
       "      <td>2.555847e-04</td>\n",
       "      <td>7.956237e-03</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.005344</td>\n",
       "      <td>9.615009e-01</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>2.273917e-05</td>\n",
       "      <td>2.980232e-08</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.490116e-07</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>3.576279e-07</td>\n",
       "      <td>4.053116e-06</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0.999934</td>\n",
       "      <td>4.871343e-03</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>1.118699e-05</td>\n",
       "      <td>5.359103e-04</td>\n",
       "      <td>straightregular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>0.006526</td>\n",
       "      <td>2.550067e-04</td>\n",
       "      <td>0.012970</td>\n",
       "      <td>3.049978e-05</td>\n",
       "      <td>3.408970e-06</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     straightregular    semifitted   relaxed     oversized  fittedtailored  \\\n",
       "0           0.466508  1.281500e-04  0.065370  2.604723e-05    9.627302e-01   \n",
       "1           0.000039  4.094937e-02  0.000017  5.698204e-05    2.086163e-07   \n",
       "2           0.000020  1.686387e-01  0.983514  1.788139e-07    7.907152e-04   \n",
       "3           0.000819  2.659559e-04  0.767777  1.189113e-05    4.231930e-06   \n",
       "4           0.000077  9.986877e-01  0.000117  7.748604e-07    7.152557e-07   \n",
       "..               ...           ...       ...           ...             ...   \n",
       "917         0.000030  3.337860e-05  0.889967  2.555847e-04    7.956237e-03   \n",
       "918         0.005344  9.615009e-01  0.000728  2.273917e-05    2.980232e-08   \n",
       "919         0.000017  1.490116e-07  0.041814  3.576279e-07    4.053116e-06   \n",
       "920         0.999934  4.871343e-03  0.000805  1.118699e-05    5.359103e-04   \n",
       "921         0.006526  2.550067e-04  0.012970  3.049978e-05    3.408970e-06   \n",
       "\n",
       "         predict_fit  \n",
       "0     fittedtailored  \n",
       "1         semifitted  \n",
       "2            relaxed  \n",
       "3            relaxed  \n",
       "4         semifitted  \n",
       "..               ...  \n",
       "917          relaxed  \n",
       "918       semifitted  \n",
       "919          relaxed  \n",
       "920  straightregular  \n",
       "921          relaxed  \n",
       "\n",
       "[922 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part ll: Fit prediction on full data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This main() function will predict the fit of the clothing. It takes a CSV file as an input. The CSV file needs to have \"brand\", \"product_full_name\", \"description\", and \"details\" columns. The function will output a CSV file with an additional fit column and return the dataframe. \n",
    "- Link to the saved Keras models and tokenizer: https://drive.google.com/file/d/1QZ1hVUlboyCnOFILYwfMbsKlhQHJAIBb/view?usp=sharing Please kindly download the Models.zip file before running the main() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.models import load_model\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "startTime = pd.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "def removePunctuation(text, punctuations=string.punctuation+\"``\"+\"’\"+\"”\"):\n",
    "    words=nltk.word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in punctuations]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = set(stopwords.words(\"English\"))\n",
    "def removeStopwords(text, stopwords=nltk_stopwords):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    newWords = [word for word in words if word.lower() not in stopwords]\n",
    "    cleanedText = \" \".join(newWords)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatizedWords = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "    lemmatizedText = \" \".join(lemmatizedWords)\n",
    "    return lemmatizedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, columns = [\"brand\", \"product_full_name\", \"description\", \"details\"]):\n",
    "    df['details'] = df['details'].str.replace(\"\\n\", \"\")\n",
    "    #replace null values with UNKNOWN_TOKEN\n",
    "    df['brand'] = df['brand'].fillna('UNKNOWN_TOKEN')\n",
    "    df['description'] = df['description'].fillna('UNKNOWN_TOKEN')\n",
    "    df['details'] = df['details'].fillna('UNKNOWN_TOKEN')\n",
    "    df['product_full_name'] = df['product_full_name'].fillna('UNKNOWN_TOKEN')\n",
    "    #remove punctuation and stopwords then lemmatize\n",
    "    for col in columns: \n",
    "        df[col] = df[col].apply(removePunctuation)\n",
    "        df[col] = df[col].apply(removeStopwords)\n",
    "        df[col] = df[col].apply(lemmatize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_token_length_per_doc(docs):\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test_df, target, max_length):\n",
    "    #load data\n",
    "    X_test_df[\"input_doc\"] = X_test_df.brand + \" \" + X_test_df.product_full_name + \" \" \\\n",
    "                                + X_test_df.description + \" \" + X_test_df.details \n",
    "    X_test = X_test_df.loc[:, \"input_doc\"].values\n",
    "    test_docs = list(X_test)\n",
    "\n",
    "    #load model\n",
    "    model = load_model(\"{}_model.h5\".format(target))\n",
    "    with open('{}_tokenizer.pickle'.format(target), 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "        \n",
    "    #predict\n",
    "    encoded_test_docs = integer_encode_documents(test_docs, tokenizer)\n",
    "    padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "    prediction_proba = model.predict(padded_test_docs, verbose = 0)\n",
    "    \n",
    "    return prediction_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''\n",
    "    This function will predict the fit of the clothing. It takes a CSV file as an input. The CSV file needs to have \n",
    "    \"brand\", \"product_full_name\", \"description\", and \"details\" columns. The function will output a CSV file with an \n",
    "    additional fit column and return the dataframe. \n",
    "    '''\n",
    "    #load data\n",
    "    inputFile = input(\"What's the name of the csv file? (ex. full_data.csv)\")\n",
    "    fullData = pd.read_csv(inputFile)\n",
    "    #Preprocess data\n",
    "    print(\"Start preprocessing data...\")\n",
    "    testData = fullData.copy()\n",
    "    testData = testData.loc[:, [\"brand\", \"product_full_name\", \"description\", \"details\"]]\n",
    "    testData = preprocessing(testData)\n",
    "    print(\"Start predicting fit...\")\n",
    "    #Predict fit\n",
    "    maxLengthDict = {'straightregular': 185,\n",
    "                 'semifitted': 185,\n",
    "                 'relaxed': 202,\n",
    "                 'oversized': 202,\n",
    "                 'fittedtailored': 202}\n",
    "    prob_df = pd.DataFrame()\n",
    "    fitType = ['straightregular', 'semifitted', 'relaxed', 'oversized', 'fittedtailored']\n",
    "    for fit in fitType:\n",
    "        prediction_proba = predict(testData, target = fit, max_length = maxLengthDict[fit])\n",
    "        prob_df[fit] = prediction_proba.flatten()\n",
    "        print(fit, \"fit prediction done\")\n",
    "    prob_df['predict_fit'] = prob_df.idxmax(axis=1)\n",
    "    fullData['fit'] = prob_df['predict_fit']\n",
    "    fullData.to_csv(\"full_data with fit prediction.csv\")\n",
    "    return fullData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the name of the csv file? (ex. full_data.csv)full_data_final version.csv\n",
      "Start preprocessing data...\n",
      "Start predicting fit...\n",
      "straightregular fit prediction done\n",
      "semifitted fit prediction done\n",
      "relaxed fit prediction done\n",
      "oversized fit prediction done\n",
      "fittedtailored fit prediction done\n"
     ]
    }
   ],
   "source": [
    "df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>514683</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:37:15.719107+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straightregular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>526676</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:36:50.682513+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>4.001E+11</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>2019-11-13 17:33:59.581661+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DSJVKJNS6F4KQ1QM6YYK9AW2</td>\n",
       "      <td>Converse</td>\n",
       "      <td>4.00012E+11</td>\n",
       "      <td>Baby's &amp; Little Kid's All-Star Two-Tone Mid-To...</td>\n",
       "      <td>The iconic mid-top design gets an added dose o...</td>\n",
       "      <td>JustKids/Shoes/Baby024Months/BabyGirl,JustKids...</td>\n",
       "      <td>2019-11-13 17:05:05.203733+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/converse-babys...</td>\n",
       "      <td>Canvas upper Round toe Lace-up vamp SmartFOAM ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semifitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DSK15ZD4D5A0QXA8NSD25YXE</td>\n",
       "      <td>Alexander McQueen</td>\n",
       "      <td>4.00011E+11</td>\n",
       "      <td>64MM Rimless Sunglasses</td>\n",
       "      <td>Hexagonal shades offer a rimless view with int...</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval</td>\n",
       "      <td>2019-11-13 18:42:30.941321+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/alexander-mcqu...</td>\n",
       "      <td>100% UV protection Gradient lenses Adjustable ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id              brand          mpn  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416    Banana Republic       514683   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065    Banana Republic       526676   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN              Loewe    4.001E+11   \n",
       "3  01DSJVKJNS6F4KQ1QM6YYK9AW2           Converse  4.00012E+11   \n",
       "4  01DSK15ZD4D5A0QXA8NSD25YXE  Alexander McQueen  4.00011E+11   \n",
       "\n",
       "                                   product_full_name  \\\n",
       "0                                   Ankle-Strap Pump   \n",
       "1                                Petite Tie-Neck Top   \n",
       "2               52MM Padded Leather Round Sunglasses   \n",
       "3  Baby's & Little Kid's All-Star Two-Tone Mid-To...   \n",
       "4                            64MM Rimless Sunglasses   \n",
       "\n",
       "                                         description  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2    Padded leather covers classic round sunglasses.   \n",
       "3  The iconic mid-top design gets an added dose o...   \n",
       "4  Hexagonal shades offer a rimless view with int...   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "3  JustKids/Shoes/Baby024Months/BabyGirl,JustKids...   \n",
       "4     JewelryAccessories/SunglassesReaders/RoundOval   \n",
       "\n",
       "                      created_at                     updated_at deleted_at  \\\n",
       "0  2019-11-11 22:37:15.719107+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "1  2019-11-11 22:36:50.682513+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "2  2019-11-13 17:33:59.581661+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "3  2019-11-13 17:05:05.203733+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "4  2019-11-13 18:42:30.941321+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "3  https://www.saksfifthavenue.com/converse-babys...   \n",
       "4  https://www.saksfifthavenue.com/alexander-mcqu...   \n",
       "\n",
       "                                             details            labels  \\\n",
       "0  A modern pump, in a rounded silhouette with an...  {\"Needs Review\"}   \n",
       "1  Dress it down with jeans and sneakers or dress...  {\"Needs Review\"}   \n",
       "2  100% UV protection Case and cleaning cloth inc...  {\"Needs Review\"}   \n",
       "3  Canvas upper Round toe Lace-up vamp SmartFOAM ...  {\"Needs Review\"}   \n",
       "4  100% UV protection Gradient lenses Adjustable ...  {\"Needs Review\"}   \n",
       "\n",
       "   bc_product_id              fit  \n",
       "0            NaN  straightregular  \n",
       "1            NaN       semifitted  \n",
       "2            NaN       semifitted  \n",
       "3            NaN       semifitted  \n",
       "4            NaN          relaxed  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime:  0:02:14.868643\n"
     ]
    }
   ],
   "source": [
    "print(\"Total runtime: \", pd.datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
