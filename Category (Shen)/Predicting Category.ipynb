{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Category\n",
    "According to Womens+Attributes.xlsx, general category has 6 attributes: top, bottom, onepiece, shoe, handbag and scarf. From tagged data, attributes include top, bottom, onepiece, shoe, sweater, accessory, blazer, hoodie etc. To combine these two categorization, I chose to keep top, bottom, onepiece, shoe, accessory only and blazer, sweater and hoodie are included in top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "import spacy\n",
    "max_iter = 20000\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "parser = English()\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    use regular expression to clean text \n",
    "    replace numbers and units to variables\n",
    "    '''\n",
    "    p = re.compile(r'<.*?>')\n",
    "    text = p.sub('', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\xa0', '',text)\n",
    "    text = re.sub(r'\\d{1,3}(\\.|\\’)?\\d{1,3}?(\\\"|\\”)',\"length_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?%',\"percentage_val\", text)\n",
    "    text = text.strip(string.punctuation).replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?mm',\"mm_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?cm',\"cm_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?(inches|inch)',\"inches_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?(lbs|kg)',\"weight_val\", text)\n",
    "    text = re.sub(r'size\\s*?\\d{1,3}\\s*?',\"size_val\", text)\n",
    "    text = re.sub(r'\\b\\d+\\b',' ',text)\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    return text\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    "    '''\n",
    "    Tokenize and lemmatize texts and remove stopwords\n",
    "    '''\n",
    "    mytokens = parser(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cate_train(inputFile):\n",
    "    '''\n",
    "    Input training dataset file\n",
    "    Keep relevant columns \n",
    "    Basic cleaning\n",
    "    Output cleaned training dataset for category in a dataframe\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    train_data = pd.read_csv(inputFile)\n",
    "    train_data = train_data[['product_id', 'product_color_id','brand', 'brand_category','product_full_name', 'description',  'details','attribute_name', 'attribute_value']]\n",
    "    train_data.drop_duplicates(inplace = True)\n",
    "    train_data_cate = train_data[train_data.attribute_name.str.lower() == 'category']\n",
    "    train_data_cate.attribute_value = train_data_cate.attribute_value.str.lower()\n",
    "    attribute_value = ['top'   if i in ['blazerscoatsjackets', 'blazers, coats & jackets','sweatshirthoodie', 'sweater', 'sweatshirt & hoodie','sweatshirt & hoodie'] else i.lower() for i in train_data_cate.attribute_value]\n",
    "    attribute_value = ['onepiece'   if i in ['one piece', 'one-piece'] else i.lower() for i in attribute_value]\n",
    "    train_data_cate.attribute_value = attribute_value\n",
    "    train_data_cate.fillna('Unknown_token', inplace = True)    \n",
    "    dummies = pd.get_dummies(train_data_cate['attribute_value'])\n",
    "    train_data_cate = pd.concat([train_data_cate, dummies], axis = 1)\n",
    "    train_data_cate.reset_index(inplace = True)\n",
    "    train_data_cate = train_data_cate.drop('index', axis = 1)\n",
    "    X = train_data_cate['description'] + ' '+train_data_cate['product_full_name'] + ' '+train_data_cate['details'] + ' '+train_data_cate['brand_category']\n",
    "    df_y = pd.DataFrame(train_data_cate.iloc[:,-5:], index = train_data_cate.index)\n",
    "    X = [clean_text(i) for i in X]\n",
    "    return train_data_cate, X, df_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "parser = English()\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    use regular expression to clean text \n",
    "    replace numbers and units to variables\n",
    "    '''\n",
    "    p = re.compile(r'<.*?>')\n",
    "    text = p.sub('', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\xa0', '',text)\n",
    "    text = re.sub(r'\\d{1,3}(\\.|\\’)?\\d{1,3}?(\\\"|\\”)',\"length_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?%',\"percentage_val\", text)\n",
    "    text = text.strip(string.punctuation).replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?mm',\"mm_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?cm',\"cm_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?(inches|inch)',\"inches_val\", text)\n",
    "    text = re.sub(r'\\d{1,3}\\s*?(lbs|kg)',\"weight_val\", text)\n",
    "    text = re.sub(r'size\\s*?\\d{1,3}\\s*?',\"size_val\", text)\n",
    "    text = re.sub(r'\\b\\d+\\b',' ',text)\n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    mytokens = parser(text)\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "    return \" \".join(mytokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cate_test(inputFile):\n",
    "    '''\n",
    "    Input testing dataset that is going to be labeled\n",
    "    Keep relevant columns \n",
    "    Basic cleaning\n",
    "    Output cleaned testing dataset for category in a dataframe\n",
    "    '''\n",
    "    full_test_data = pd.read_csv(inputFile)\n",
    "    test_data = full_test_data[['product_full_name', 'details','description', 'brand_category']]\n",
    "    test_data.fillna('Unknown_token', inplace = True)\n",
    "    X_test = test_data['product_full_name'] + ' '+ test_data['details'] + ' '+test_data['description']+ ' '+test_data['brand_category']\n",
    "    return test_data, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_token_length_per_doc(docs):\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_classes(mat):\n",
    "    pred = list(map(lambda v: list(np.argsort(v))[-1:], mat))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_classes(df):\n",
    "    tclas=list()\n",
    "    for v in df.values:\n",
    "        tl = []\n",
    "        for i,a in enumerate(v):\n",
    "            if a == 1:\n",
    "                tl.append(i)\n",
    "        tclas.append(tl)\n",
    "    return tclas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(l1,l2):\n",
    "    \n",
    "    m=0\n",
    "    for i in range(len(l2)):\n",
    "        pred = set(l1[i])\n",
    "        true = set(l2[i])\n",
    "        \n",
    "        if len(pred.intersection(true)) != 0:\n",
    "            m += 1\n",
    "    return m/len(l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cate, X_clean, y_clean = clean_cate_train('new_merged_15W.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = get_max_token_length_per_doc(X_clean)\n",
    "tk = Tokenizer(oov_token = 'Unknown_token')\n",
    "tk.fit_on_texts(X_clean)\n",
    "vocab_size = len(tk.word_index) + 1\n",
    "vector_text = tk.texts_to_sequences(X_clean)\n",
    "padded_token_lists = pad_sequences(vector_text, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.DataFrame(padded_token_lists, index = train_data_cate.index)\n",
    "df_y = pd.DataFrame(train_data_cate.iloc[:,-5:], index = train_data_cate.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x,df_y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f82e643c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50,activation='tanh'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size=200,epochs=100,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vectors_train = model.predict(X_train)\n",
    "pred_vectors_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_classes = get_pred_classes(pred_vectors_train)\n",
    "test_pred_classes = get_pred_classes(pred_vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true_classes = get_true_classes(y_train)\n",
    "test_true_classes = get_true_classes(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991616013414378"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(train_pred_classes,train_true_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9931573802541545"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(test_pred_classes,test_true_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using all tagged data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cate, X_train, y_train = clean_cate_train('new_merged_15W.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = get_max_token_length_per_doc(X_train)\n",
    "tk = Tokenizer(oov_token = 'Unknown_token')\n",
    "tk.fit_on_texts(X_train)\n",
    "vocab_size = len(tk.word_index) + 1\n",
    "vector_text = tk.texts_to_sequences(X_train)\n",
    "padded_token_lists = pad_sequences(vector_text, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.DataFrame(padded_token_lists, index = train_data_cate.index)\n",
    "df_y = pd.DataFrame(train_data_cate.iloc[:,-5:], index = train_data_cate.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f82c95d448>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50,activation='tanh'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(df_x,df_y,batch_size=200,epochs=100,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkl_Filename = \"category_model.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkl_Filename = \"category_token.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(tk, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict full data set using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data, X_test = clean_cate_test('full_data_final version.csv')\n",
    "X_test = X_test.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_text_test = tk.texts_to_sequences(X_test)\n",
    "padded_token_lists_test = pad_sequences(vector_text_test, maxlen=max_length, padding='post')\n",
    "X_test = pd.DataFrame(padded_token_lists_test, index = full_test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_vectors_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_classes = get_pred_classes(pred_vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(y_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_pred = [categories[i[0]] for i in test_pred_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = pd.Series(cate_pred).str.capitalize() \n",
    "full_test_data['category']  = predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>details</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Onepiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>Accessory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baby's &amp; Little Kid's All-Star Two-Tone Mid-To...</td>\n",
       "      <td>Canvas upper Round toe Lace-up vamp SmartFOAM ...</td>\n",
       "      <td>The iconic mid-top design gets an added dose o...</td>\n",
       "      <td>JustKids/Shoes/Baby024Months/BabyGirl,JustKids...</td>\n",
       "      <td>Shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64MM Rimless Sunglasses</td>\n",
       "      <td>100% UV protection Gradient lenses Adjustable ...</td>\n",
       "      <td>Hexagonal shades offer a rimless view with int...</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval</td>\n",
       "      <td>Accessory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48974</th>\n",
       "      <td>Baby's Hooded Jacket</td>\n",
       "      <td>Cozy double breasted jacket crafted from cotto...</td>\n",
       "      <td>Unknown_token</td>\n",
       "      <td>JustKids/Baby024months/InfantGirls/Outerwear</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48975</th>\n",
       "      <td>Flawless Fusion Ultra-Longwear Foundation</td>\n",
       "      <td>WHAT IT ISA 15-hour long wearing, water resist...</td>\n",
       "      <td>WHAT IT ISA 15-hour long wearing, water resist...</td>\n",
       "      <td>SaksBeautyPlace/ForHer/Color/Foundation/Liquid...</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48976</th>\n",
       "      <td>Baby Girl's 2-Piece Ruffle Sweatshirt &amp; Stripe...</td>\n",
       "      <td>Crewneck Long sleeves Rib-knit neck, cuffs and...</td>\n",
       "      <td>Ruffled-trim sweatshirt lends romance to this ...</td>\n",
       "      <td>JustKids/Baby024months/InfantGirls/Tops,JustKi...</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48977</th>\n",
       "      <td>Little Girl's Plaid &amp; Velvet Dress</td>\n",
       "      <td>Peter Pan collar Short sleeves Back zipper Two...</td>\n",
       "      <td>Pretty plaid dress with velvet collar and velv...</td>\n",
       "      <td>JustKids/Girls214/ToddlerGirls24/Dresses,JustK...</td>\n",
       "      <td>Onepiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48978</th>\n",
       "      <td>Baby Girl's Short-Sleeve Dress</td>\n",
       "      <td>Corduroy dress with bow Cotton corduroy Web gr...</td>\n",
       "      <td>Unknown_token</td>\n",
       "      <td>JustKids/Baby024months/InfantGirls/Dresses</td>\n",
       "      <td>Bottom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48979 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       product_full_name  \\\n",
       "0                                       Ankle-Strap Pump   \n",
       "1                                    Petite Tie-Neck Top   \n",
       "2                   52MM Padded Leather Round Sunglasses   \n",
       "3      Baby's & Little Kid's All-Star Two-Tone Mid-To...   \n",
       "4                                64MM Rimless Sunglasses   \n",
       "...                                                  ...   \n",
       "48974                               Baby's Hooded Jacket   \n",
       "48975          Flawless Fusion Ultra-Longwear Foundation   \n",
       "48976  Baby Girl's 2-Piece Ruffle Sweatshirt & Stripe...   \n",
       "48977                 Little Girl's Plaid & Velvet Dress   \n",
       "48978                     Baby Girl's Short-Sleeve Dress   \n",
       "\n",
       "                                                 details  \\\n",
       "0      A modern pump, in a rounded silhouette with an...   \n",
       "1      Dress it down with jeans and sneakers or dress...   \n",
       "2      100% UV protection Case and cleaning cloth inc...   \n",
       "3      Canvas upper Round toe Lace-up vamp SmartFOAM ...   \n",
       "4      100% UV protection Gradient lenses Adjustable ...   \n",
       "...                                                  ...   \n",
       "48974  Cozy double breasted jacket crafted from cotto...   \n",
       "48975  WHAT IT ISA 15-hour long wearing, water resist...   \n",
       "48976  Crewneck Long sleeves Rib-knit neck, cuffs and...   \n",
       "48977  Peter Pan collar Short sleeves Back zipper Two...   \n",
       "48978  Corduroy dress with bow Cotton corduroy Web gr...   \n",
       "\n",
       "                                             description  \\\n",
       "0      A modern pump, in a rounded silhouette with an...   \n",
       "1      Dress it down with jeans and sneakers or dress...   \n",
       "2        Padded leather covers classic round sunglasses.   \n",
       "3      The iconic mid-top design gets an added dose o...   \n",
       "4      Hexagonal shades offer a rimless view with int...   \n",
       "...                                                  ...   \n",
       "48974                                      Unknown_token   \n",
       "48975  WHAT IT ISA 15-hour long wearing, water resist...   \n",
       "48976  Ruffled-trim sweatshirt lends romance to this ...   \n",
       "48977  Pretty plaid dress with velvet collar and velv...   \n",
       "48978                                      Unknown_token   \n",
       "\n",
       "                                          brand_category   category  \n",
       "0                                                Unknown       Shoe  \n",
       "1                                                Unknown   Onepiece  \n",
       "2      JewelryAccessories/SunglassesReaders/RoundOval...  Accessory  \n",
       "3      JustKids/Shoes/Baby024Months/BabyGirl,JustKids...       Shoe  \n",
       "4         JewelryAccessories/SunglassesReaders/RoundOval  Accessory  \n",
       "...                                                  ...        ...  \n",
       "48974       JustKids/Baby024months/InfantGirls/Outerwear        Top  \n",
       "48975  SaksBeautyPlace/ForHer/Color/Foundation/Liquid...        Top  \n",
       "48976  JustKids/Baby024months/InfantGirls/Tops,JustKi...        Top  \n",
       "48977  JustKids/Girls214/ToddlerGirls24/Dresses,JustK...   Onepiece  \n",
       "48978         JustKids/Baby024months/InfantGirls/Dresses     Bottom  \n",
       "\n",
       "[48979 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data.to_csv('predicted_category.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
